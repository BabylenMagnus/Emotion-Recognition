{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from model import SimpleCNN\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "BS = 50\n",
    "num_classes = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/evgeniy/Seagate Expansion Drive/код/EmotionRecognition'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(48),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'train': datasets.ImageFolder('data/train/', transform=transform['train']),\n",
    "    'test': datasets.ImageFolder('data/test/', transform=transform['train'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35640, 247)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size = len(data['train'])\n",
    "test_data_size = len(data['test'])\n",
    "train_data_size, test_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(data['train'], shuffle=True, batch_size=256,\n",
    "                        num_workers=6)\n",
    "test_data = DataLoader(data['test'], batch_size=247, shuffle=True,\n",
    "                       num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleCNN().to(device)\n",
    "model = torch.load('EmotionClassificationCNN.4500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surpise': 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=5e-4, nesterov=True, momentum=0.1)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surpise': 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_to_idx = data['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pred): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=7, bias=True)\n",
       "    (4): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000\n",
      "Training: Loss: 1.4464\n",
      "Epoch: 2/1000\n",
      "Training: Loss: 1.3788\n",
      "Epoch: 3/1000\n",
      "Training: Loss: 1.5112\n",
      "Epoch: 4/1000\n",
      "Training: Loss: 1.4119\n",
      "Epoch: 5/1000\n",
      "Training: Loss: 1.3164\n",
      "Epoch: 6/1000\n",
      "Training: Loss: 1.3993\n",
      "Epoch: 7/1000\n",
      "Training: Loss: 1.3731\n",
      "Epoch: 8/1000\n",
      "Training: Loss: 1.5004\n",
      "Epoch: 9/1000\n",
      "Training: Loss: 1.4642\n",
      "Epoch: 10/1000\n",
      "Training: Loss: 1.4695\n",
      "Epoch: 11/1000\n",
      "Training: Loss: 1.4252\n",
      "Epoch: 12/1000\n",
      "Training: Loss: 1.2764\n",
      "Epoch: 13/1000\n",
      "Training: Loss: 1.4095\n",
      "Epoch: 14/1000\n",
      "Training: Loss: 1.3192\n",
      "Epoch: 15/1000\n",
      "Training: Loss: 1.3290\n",
      "Epoch: 16/1000\n",
      "Training: Loss: 1.4792\n",
      "Epoch: 17/1000\n",
      "Training: Loss: 1.3940\n",
      "Epoch: 18/1000\n",
      "Training: Loss: 1.3778\n",
      "Epoch: 19/1000\n",
      "Training: Loss: 1.4326\n",
      "Epoch: 20/1000\n",
      "Training: Loss: 1.3884\n",
      "Epoch: 21/1000\n",
      "Training: Loss: 1.5136\n",
      "Epoch: 22/1000\n",
      "Training: Loss: 1.3435\n",
      "Epoch: 23/1000\n",
      "Training: Loss: 1.4326\n",
      "Epoch: 24/1000\n",
      "Training: Loss: 1.3777\n",
      "Epoch: 25/1000\n",
      "Training: Loss: 1.3804\n",
      "Epoch: 26/1000\n",
      "Training: Loss: 1.4097\n",
      "Epoch: 27/1000\n",
      "Training: Loss: 1.3819\n",
      "Epoch: 28/1000\n",
      "Training: Loss: 1.4395\n",
      "Epoch: 29/1000\n",
      "Training: Loss: 1.3852\n",
      "Epoch: 30/1000\n",
      "Training: Loss: 1.4370\n",
      "Epoch: 31/1000\n",
      "Training: Loss: 1.2690\n",
      "Epoch: 32/1000\n",
      "Training: Loss: 1.4204\n",
      "Epoch: 33/1000\n",
      "Training: Loss: 1.5027\n",
      "Epoch: 34/1000\n",
      "Training: Loss: 1.4572\n",
      "Epoch: 35/1000\n",
      "Training: Loss: 1.5195\n",
      "Epoch: 36/1000\n",
      "Training: Loss: 1.3887\n",
      "Epoch: 37/1000\n",
      "Training: Loss: 1.4525\n",
      "Epoch: 38/1000\n",
      "Training: Loss: 1.4591\n",
      "Epoch: 39/1000\n",
      "Training: Loss: 1.4239\n",
      "Epoch: 40/1000\n",
      "Training: Loss: 1.4830\n",
      "Epoch: 41/1000\n",
      "Training: Loss: 1.4393\n",
      "Epoch: 42/1000\n",
      "Training: Loss: 1.3480\n",
      "Epoch: 43/1000\n",
      "Training: Loss: 1.4159\n",
      "Epoch: 44/1000\n",
      "Training: Loss: 1.3390\n",
      "Epoch: 45/1000\n",
      "Training: Loss: 1.3730\n",
      "Epoch: 46/1000\n",
      "Training: Loss: 1.3646\n",
      "Epoch: 47/1000\n",
      "Training: Loss: 1.3792\n",
      "Epoch: 48/1000\n",
      "Training: Loss: 1.3981\n",
      "Epoch: 49/1000\n",
      "Training: Loss: 1.4173\n",
      "Epoch: 50/1000\n",
      "Training: Loss: 1.3588\n",
      "Epoch: 51/1000\n",
      "Training: Loss: 1.4818\n",
      "Epoch: 52/1000\n",
      "Training: Loss: 1.4255\n",
      "Epoch: 53/1000\n",
      "Training: Loss: 1.3594\n",
      "Epoch: 54/1000\n",
      "Training: Loss: 1.4450\n",
      "Epoch: 55/1000\n",
      "Training: Loss: 1.4543\n",
      "Epoch: 56/1000\n",
      "Training: Loss: 1.3781\n",
      "Epoch: 57/1000\n",
      "Training: Loss: 1.4377\n",
      "Epoch: 58/1000\n",
      "Training: Loss: 1.4205\n",
      "Epoch: 59/1000\n",
      "Training: Loss: 1.3909\n",
      "Epoch: 60/1000\n",
      "Training: Loss: 1.3927\n",
      "Epoch: 61/1000\n",
      "Training: Loss: 1.4700\n",
      "Epoch: 62/1000\n",
      "Training: Loss: 1.4323\n",
      "Epoch: 63/1000\n",
      "Training: Loss: 1.3570\n",
      "Epoch: 64/1000\n",
      "Training: Loss: 1.4156\n",
      "Epoch: 65/1000\n",
      "Training: Loss: 1.3511\n",
      "Epoch: 66/1000\n",
      "Training: Loss: 1.3353\n",
      "Epoch: 67/1000\n",
      "Training: Loss: 1.2607\n",
      "Epoch: 68/1000\n",
      "Training: Loss: 1.5554\n",
      "Epoch: 69/1000\n",
      "Training: Loss: 1.4164\n",
      "Epoch: 70/1000\n",
      "Training: Loss: 1.4662\n",
      "Epoch: 71/1000\n",
      "Training: Loss: 1.3971\n",
      "Epoch: 72/1000\n",
      "Training: Loss: 1.3639\n",
      "Epoch: 73/1000\n",
      "Training: Loss: 1.4145\n",
      "Epoch: 74/1000\n",
      "Training: Loss: 1.4514\n",
      "Epoch: 75/1000\n",
      "Training: Loss: 1.5755\n",
      "Epoch: 76/1000\n",
      "Training: Loss: 1.3581\n",
      "Epoch: 77/1000\n",
      "Training: Loss: 1.4268\n",
      "Epoch: 78/1000\n",
      "Training: Loss: 1.3665\n",
      "Epoch: 79/1000\n",
      "Training: Loss: 1.4432\n",
      "Epoch: 80/1000\n",
      "Training: Loss: 1.3982\n",
      "Epoch: 81/1000\n",
      "Training: Loss: 1.4672\n",
      "Epoch: 82/1000\n",
      "Training: Loss: 1.5183\n",
      "Epoch: 83/1000\n",
      "Training: Loss: 1.3773\n",
      "Epoch: 84/1000\n",
      "Training: Loss: 1.4640\n",
      "Epoch: 85/1000\n",
      "Training: Loss: 1.3944\n",
      "Epoch: 86/1000\n",
      "Training: Loss: 1.3140\n",
      "Epoch: 87/1000\n",
      "Training: Loss: 1.3538\n",
      "Epoch: 88/1000\n",
      "Training: Loss: 1.3442\n",
      "Epoch: 89/1000\n",
      "Training: Loss: 1.3656\n",
      "Epoch: 90/1000\n",
      "Training: Loss: 1.4140\n",
      "Epoch: 91/1000\n",
      "Training: Loss: 1.3435\n",
      "Epoch: 92/1000\n",
      "Training: Loss: 1.5608\n",
      "Epoch: 93/1000\n",
      "Training: Loss: 1.3737\n",
      "Epoch: 94/1000\n",
      "Training: Loss: 1.4445\n",
      "Epoch: 95/1000\n",
      "Training: Loss: 1.4023\n",
      "Epoch: 96/1000\n",
      "Training: Loss: 1.4338\n",
      "Epoch: 97/1000\n",
      "Training: Loss: 1.4588\n",
      "Epoch: 98/1000\n",
      "Training: Loss: 1.3781\n",
      "Epoch: 99/1000\n",
      "Training: Loss: 1.5518\n",
      "Epoch: 100/1000\n",
      "Training: Loss: 1.3949\n",
      "Epoch: 101/1000\n",
      "Training: Loss: 1.4791\n",
      "Epoch: 102/1000\n",
      "Training: Loss: 1.3934\n",
      "Epoch: 103/1000\n",
      "Training: Loss: 1.3967\n",
      "Epoch: 104/1000\n",
      "Training: Loss: 1.3526\n",
      "Epoch: 105/1000\n",
      "Training: Loss: 1.5066\n",
      "Epoch: 106/1000\n",
      "Training: Loss: 1.3794\n",
      "Epoch: 107/1000\n",
      "Training: Loss: 1.4754\n",
      "Epoch: 108/1000\n",
      "Training: Loss: 1.5212\n",
      "Epoch: 109/1000\n",
      "Training: Loss: 1.3780\n",
      "Epoch: 110/1000\n",
      "Training: Loss: 1.3816\n",
      "Epoch: 111/1000\n",
      "Training: Loss: 1.4796\n",
      "Epoch: 112/1000\n",
      "Training: Loss: 1.4888\n",
      "Epoch: 113/1000\n",
      "Training: Loss: 1.4818\n",
      "Epoch: 114/1000\n",
      "Training: Loss: 1.3956\n",
      "Epoch: 115/1000\n",
      "Training: Loss: 1.4851\n",
      "Epoch: 116/1000\n",
      "Training: Loss: 1.4269\n",
      "Epoch: 117/1000\n",
      "Training: Loss: 1.3604\n",
      "Epoch: 118/1000\n",
      "Training: Loss: 1.4204\n",
      "Epoch: 119/1000\n",
      "Training: Loss: 1.4006\n",
      "Epoch: 120/1000\n",
      "Training: Loss: 1.4573\n",
      "Epoch: 121/1000\n",
      "Training: Loss: 1.3948\n",
      "Epoch: 122/1000\n",
      "Training: Loss: 1.4541\n",
      "Epoch: 123/1000\n",
      "Training: Loss: 1.4007\n",
      "Epoch: 124/1000\n",
      "Training: Loss: 1.4275\n",
      "Epoch: 125/1000\n",
      "Training: Loss: 1.3317\n",
      "Epoch: 126/1000\n",
      "Training: Loss: 1.4690\n",
      "Epoch: 127/1000\n",
      "Training: Loss: 1.4723\n",
      "Epoch: 128/1000\n",
      "Training: Loss: 1.4277\n",
      "Epoch: 129/1000\n",
      "Training: Loss: 1.4434\n",
      "Epoch: 130/1000\n",
      "Training: Loss: 1.3851\n",
      "Epoch: 131/1000\n",
      "Training: Loss: 1.4598\n",
      "Epoch: 132/1000\n",
      "Training: Loss: 1.3518\n",
      "Epoch: 133/1000\n",
      "Training: Loss: 1.4210\n",
      "Epoch: 134/1000\n",
      "Training: Loss: 1.3793\n",
      "Epoch: 135/1000\n",
      "Training: Loss: 1.4273\n",
      "Epoch: 136/1000\n",
      "Training: Loss: 1.4647\n",
      "Epoch: 137/1000\n",
      "Training: Loss: 1.3311\n",
      "Epoch: 138/1000\n",
      "Training: Loss: 1.3495\n",
      "Epoch: 139/1000\n",
      "Training: Loss: 1.4095\n",
      "Epoch: 140/1000\n",
      "Training: Loss: 1.3114\n",
      "Epoch: 141/1000\n",
      "Training: Loss: 1.3939\n",
      "Epoch: 142/1000\n",
      "Training: Loss: 1.3786\n",
      "Epoch: 143/1000\n",
      "Training: Loss: 1.3956\n",
      "Epoch: 144/1000\n",
      "Training: Loss: 1.3686\n",
      "Epoch: 145/1000\n",
      "Training: Loss: 1.3761\n",
      "Epoch: 146/1000\n",
      "Training: Loss: 1.3883\n",
      "Epoch: 147/1000\n",
      "Training: Loss: 1.4498\n",
      "Epoch: 148/1000\n",
      "Training: Loss: 1.3371\n",
      "Epoch: 149/1000\n",
      "Training: Loss: 1.4287\n",
      "Epoch: 150/1000\n",
      "Training: Loss: 1.4308\n",
      "Epoch: 151/1000\n",
      "Training: Loss: 1.4060\n",
      "Epoch: 152/1000\n",
      "Training: Loss: 1.3603\n",
      "Epoch: 153/1000\n",
      "Training: Loss: 1.3896\n",
      "Epoch: 154/1000\n",
      "Training: Loss: 1.4689\n",
      "Epoch: 155/1000\n",
      "Training: Loss: 1.4025\n",
      "Epoch: 156/1000\n",
      "Training: Loss: 1.4240\n",
      "Epoch: 157/1000\n",
      "Training: Loss: 1.3856\n",
      "Epoch: 158/1000\n",
      "Training: Loss: 1.4023\n",
      "Epoch: 159/1000\n",
      "Training: Loss: 1.4048\n",
      "Epoch: 160/1000\n",
      "Training: Loss: 1.4024\n",
      "Epoch: 161/1000\n",
      "Training: Loss: 1.4842\n",
      "Epoch: 162/1000\n",
      "Training: Loss: 1.4029\n",
      "Epoch: 163/1000\n",
      "Training: Loss: 1.4383\n",
      "Epoch: 164/1000\n",
      "Training: Loss: 1.3652\n",
      "Epoch: 165/1000\n",
      "Training: Loss: 1.4270\n",
      "Epoch: 166/1000\n",
      "Training: Loss: 1.3309\n",
      "Epoch: 167/1000\n",
      "Training: Loss: 1.3351\n",
      "Epoch: 168/1000\n",
      "Training: Loss: 1.3619\n",
      "Epoch: 169/1000\n",
      "Training: Loss: 1.4068\n",
      "Epoch: 170/1000\n",
      "Training: Loss: 1.4831\n",
      "Epoch: 171/1000\n",
      "Training: Loss: 1.4152\n",
      "Epoch: 172/1000\n",
      "Training: Loss: 1.4640\n",
      "Epoch: 173/1000\n",
      "Training: Loss: 1.3415\n",
      "Epoch: 174/1000\n",
      "Training: Loss: 1.3130\n",
      "Epoch: 175/1000\n",
      "Training: Loss: 1.3000\n",
      "Epoch: 176/1000\n",
      "Training: Loss: 1.4237\n",
      "Epoch: 177/1000\n",
      "Training: Loss: 1.4615\n",
      "Epoch: 178/1000\n",
      "Training: Loss: 1.3671\n",
      "Epoch: 179/1000\n",
      "Training: Loss: 1.4939\n",
      "Epoch: 180/1000\n",
      "Training: Loss: 1.4004\n",
      "Epoch: 181/1000\n",
      "Training: Loss: 1.3882\n",
      "Epoch: 182/1000\n",
      "Training: Loss: 1.4057\n",
      "Epoch: 183/1000\n",
      "Training: Loss: 1.3925\n",
      "Epoch: 184/1000\n",
      "Training: Loss: 1.4138\n",
      "Epoch: 185/1000\n",
      "Training: Loss: 1.4885\n",
      "Epoch: 186/1000\n",
      "Training: Loss: 1.4413\n",
      "Epoch: 187/1000\n",
      "Training: Loss: 1.4365\n",
      "Epoch: 188/1000\n",
      "Training: Loss: 1.4613\n",
      "Epoch: 189/1000\n",
      "Training: Loss: 1.3691\n",
      "Epoch: 190/1000\n",
      "Training: Loss: 1.4359\n",
      "Epoch: 191/1000\n",
      "Training: Loss: 1.3234\n",
      "Epoch: 192/1000\n",
      "Training: Loss: 1.4926\n",
      "Epoch: 193/1000\n",
      "Training: Loss: 1.3792\n",
      "Epoch: 194/1000\n",
      "Training: Loss: 1.3868\n",
      "Epoch: 195/1000\n",
      "Training: Loss: 1.4574\n",
      "Epoch: 196/1000\n",
      "Training: Loss: 1.4588\n",
      "Epoch: 197/1000\n",
      "Training: Loss: 1.4096\n",
      "Epoch: 198/1000\n",
      "Training: Loss: 1.5280\n",
      "Epoch: 199/1000\n",
      "Training: Loss: 1.5010\n",
      "Epoch: 200/1000\n",
      "Training: Loss: 1.3576\n",
      "Epoch: 201/1000\n",
      "Training: Loss: 1.4045\n",
      "Epoch: 202/1000\n",
      "Training: Loss: 1.3979\n",
      "Epoch: 203/1000\n",
      "Training: Loss: 1.3719\n",
      "Epoch: 204/1000\n",
      "Training: Loss: 1.3834\n",
      "Epoch: 205/1000\n",
      "Training: Loss: 1.3804\n",
      "Epoch: 206/1000\n",
      "Training: Loss: 1.4195\n",
      "Epoch: 207/1000\n",
      "Training: Loss: 1.4586\n",
      "Epoch: 208/1000\n",
      "Training: Loss: 1.4975\n",
      "Epoch: 209/1000\n",
      "Training: Loss: 1.4539\n",
      "Epoch: 210/1000\n",
      "Training: Loss: 1.4323\n",
      "Epoch: 211/1000\n",
      "Training: Loss: 1.3945\n",
      "Epoch: 212/1000\n",
      "Training: Loss: 1.4112\n",
      "Epoch: 213/1000\n",
      "Training: Loss: 1.5116\n",
      "Epoch: 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.4173\n",
      "Epoch: 215/1000\n",
      "Training: Loss: 1.4728\n",
      "Epoch: 216/1000\n",
      "Training: Loss: 1.3661\n",
      "Epoch: 217/1000\n",
      "Training: Loss: 1.3772\n",
      "Epoch: 218/1000\n",
      "Training: Loss: 1.4206\n",
      "Epoch: 219/1000\n",
      "Training: Loss: 1.4106\n",
      "Epoch: 220/1000\n",
      "Training: Loss: 1.5746\n",
      "Epoch: 221/1000\n",
      "Training: Loss: 1.4044\n",
      "Epoch: 222/1000\n",
      "Training: Loss: 1.3363\n",
      "Epoch: 223/1000\n",
      "Training: Loss: 1.4155\n",
      "Epoch: 224/1000\n",
      "Training: Loss: 1.3612\n",
      "Epoch: 225/1000\n",
      "Training: Loss: 1.4221\n",
      "Epoch: 226/1000\n",
      "Training: Loss: 1.4177\n",
      "Epoch: 227/1000\n",
      "Training: Loss: 1.5005\n",
      "Epoch: 228/1000\n",
      "Training: Loss: 1.3999\n",
      "Epoch: 229/1000\n",
      "Training: Loss: 1.4259\n",
      "Epoch: 230/1000\n",
      "Training: Loss: 1.4161\n",
      "Epoch: 231/1000\n",
      "Training: Loss: 1.3760\n",
      "Epoch: 232/1000\n",
      "Training: Loss: 1.4082\n",
      "Epoch: 233/1000\n",
      "Training: Loss: 1.3762\n",
      "Epoch: 234/1000\n",
      "Training: Loss: 1.4327\n",
      "Epoch: 235/1000\n",
      "Training: Loss: 1.4007\n",
      "Epoch: 236/1000\n",
      "Training: Loss: 1.4375\n",
      "Epoch: 237/1000\n",
      "Training: Loss: 1.3696\n",
      "Epoch: 238/1000\n",
      "Training: Loss: 1.4278\n",
      "Epoch: 239/1000\n",
      "Training: Loss: 1.4753\n",
      "Epoch: 240/1000\n",
      "Training: Loss: 1.3962\n",
      "Epoch: 241/1000\n",
      "Training: Loss: 1.3618\n",
      "Epoch: 242/1000\n",
      "Training: Loss: 1.3622\n",
      "Epoch: 243/1000\n",
      "Training: Loss: 1.3754\n",
      "Epoch: 244/1000\n",
      "Training: Loss: 1.4493\n",
      "Epoch: 245/1000\n",
      "Training: Loss: 1.3803\n",
      "Epoch: 246/1000\n",
      "Training: Loss: 1.3790\n",
      "Epoch: 247/1000\n",
      "Training: Loss: 1.3910\n",
      "Epoch: 248/1000\n",
      "Training: Loss: 1.3647\n",
      "Epoch: 249/1000\n",
      "Training: Loss: 1.4473\n",
      "Epoch: 250/1000\n",
      "Training: Loss: 1.4862\n",
      "Epoch: 251/1000\n",
      "Training: Loss: 1.4949\n",
      "Epoch: 252/1000\n",
      "Training: Loss: 1.3390\n",
      "Epoch: 253/1000\n",
      "Training: Loss: 1.3851\n",
      "Epoch: 254/1000\n",
      "Training: Loss: 1.5218\n",
      "Epoch: 255/1000\n",
      "Training: Loss: 1.4758\n",
      "Epoch: 256/1000\n",
      "Training: Loss: 1.4562\n",
      "Epoch: 257/1000\n",
      "Training: Loss: 1.3768\n",
      "Epoch: 258/1000\n",
      "Training: Loss: 1.4307\n",
      "Epoch: 259/1000\n",
      "Training: Loss: 1.3628\n",
      "Epoch: 260/1000\n",
      "Training: Loss: 1.4800\n",
      "Epoch: 261/1000\n",
      "Training: Loss: 1.3539\n",
      "Epoch: 262/1000\n",
      "Training: Loss: 1.4163\n",
      "Epoch: 263/1000\n",
      "Training: Loss: 1.3499\n",
      "Epoch: 264/1000\n",
      "Training: Loss: 1.3083\n",
      "Epoch: 265/1000\n",
      "Training: Loss: 1.3789\n",
      "Epoch: 266/1000\n",
      "Training: Loss: 1.4427\n",
      "Epoch: 267/1000\n",
      "Training: Loss: 1.4231\n",
      "Epoch: 268/1000\n",
      "Training: Loss: 1.3947\n",
      "Epoch: 269/1000\n",
      "Training: Loss: 1.5176\n",
      "Epoch: 270/1000\n",
      "Training: Loss: 1.3734\n",
      "Epoch: 271/1000\n",
      "Training: Loss: 1.3622\n",
      "Epoch: 272/1000\n",
      "Training: Loss: 1.4244\n",
      "Epoch: 273/1000\n",
      "Training: Loss: 1.5228\n",
      "Epoch: 274/1000\n",
      "Training: Loss: 1.3931\n",
      "Epoch: 275/1000\n",
      "Training: Loss: 1.3366\n",
      "Epoch: 276/1000\n",
      "Training: Loss: 1.4057\n",
      "Epoch: 277/1000\n",
      "Training: Loss: 1.3728\n",
      "Epoch: 278/1000\n",
      "Training: Loss: 1.3946\n",
      "Epoch: 279/1000\n",
      "Training: Loss: 1.4160\n",
      "Epoch: 280/1000\n",
      "Training: Loss: 1.4236\n",
      "Epoch: 281/1000\n",
      "Training: Loss: 1.4804\n",
      "Epoch: 282/1000\n",
      "Training: Loss: 1.3531\n",
      "Epoch: 283/1000\n",
      "Training: Loss: 1.4107\n",
      "Epoch: 284/1000\n",
      "Training: Loss: 1.3723\n",
      "Epoch: 285/1000\n",
      "Training: Loss: 1.4180\n",
      "Epoch: 286/1000\n",
      "Training: Loss: 1.4064\n",
      "Epoch: 287/1000\n",
      "Training: Loss: 1.4498\n",
      "Epoch: 288/1000\n",
      "Training: Loss: 1.3923\n",
      "Epoch: 289/1000\n",
      "Training: Loss: 1.4145\n",
      "Epoch: 290/1000\n",
      "Training: Loss: 1.4623\n",
      "Epoch: 291/1000\n",
      "Training: Loss: 1.4683\n",
      "Epoch: 292/1000\n",
      "Training: Loss: 1.4610\n",
      "Epoch: 293/1000\n",
      "Training: Loss: 1.4252\n",
      "Epoch: 294/1000\n",
      "Training: Loss: 1.3578\n",
      "Epoch: 295/1000\n",
      "Training: Loss: 1.4848\n",
      "Epoch: 296/1000\n",
      "Training: Loss: 1.3316\n",
      "Epoch: 297/1000\n",
      "Training: Loss: 1.4666\n",
      "Epoch: 298/1000\n",
      "Training: Loss: 1.3546\n",
      "Epoch: 299/1000\n",
      "Training: Loss: 1.3701\n",
      "Epoch: 300/1000\n",
      "Training: Loss: 1.4404\n",
      "Epoch: 301/1000\n",
      "Training: Loss: 1.3891\n",
      "Epoch: 302/1000\n",
      "Training: Loss: 1.4305\n",
      "Epoch: 303/1000\n",
      "Training: Loss: 1.4642\n",
      "Epoch: 304/1000\n",
      "Training: Loss: 1.4131\n",
      "Epoch: 305/1000\n",
      "Training: Loss: 1.3742\n",
      "Epoch: 306/1000\n",
      "Training: Loss: 1.4690\n",
      "Epoch: 307/1000\n",
      "Training: Loss: 1.4924\n",
      "Epoch: 308/1000\n",
      "Training: Loss: 1.4266\n",
      "Epoch: 309/1000\n",
      "Training: Loss: 1.4081\n",
      "Epoch: 310/1000\n",
      "Training: Loss: 1.3322\n",
      "Epoch: 311/1000\n",
      "Training: Loss: 1.4053\n",
      "Epoch: 312/1000\n",
      "Training: Loss: 1.3654\n",
      "Epoch: 313/1000\n",
      "Training: Loss: 1.5074\n",
      "Epoch: 314/1000\n",
      "Training: Loss: 1.3952\n",
      "Epoch: 315/1000\n",
      "Training: Loss: 1.4700\n",
      "Epoch: 316/1000\n",
      "Training: Loss: 1.4229\n",
      "Epoch: 317/1000\n",
      "Training: Loss: 1.3845\n",
      "Epoch: 318/1000\n",
      "Training: Loss: 1.5045\n",
      "Epoch: 319/1000\n",
      "Training: Loss: 1.4158\n",
      "Epoch: 320/1000\n",
      "Training: Loss: 1.3988\n",
      "Epoch: 321/1000\n",
      "Training: Loss: 1.4337\n",
      "Epoch: 322/1000\n",
      "Training: Loss: 1.3546\n",
      "Epoch: 323/1000\n",
      "Training: Loss: 1.4819\n",
      "Epoch: 324/1000\n",
      "Training: Loss: 1.4286\n",
      "Epoch: 325/1000\n",
      "Training: Loss: 1.3961\n",
      "Epoch: 326/1000\n",
      "Training: Loss: 1.3821\n",
      "Epoch: 327/1000\n",
      "Training: Loss: 1.3756\n",
      "Epoch: 328/1000\n",
      "Training: Loss: 1.4212\n",
      "Epoch: 329/1000\n",
      "Training: Loss: 1.4224\n",
      "Epoch: 330/1000\n",
      "Training: Loss: 1.4053\n",
      "Epoch: 331/1000\n",
      "Training: Loss: 1.2738\n",
      "Epoch: 332/1000\n",
      "Training: Loss: 1.3685\n",
      "Epoch: 333/1000\n",
      "Training: Loss: 1.3913\n",
      "Epoch: 334/1000\n",
      "Training: Loss: 1.4121\n",
      "Epoch: 335/1000\n",
      "Training: Loss: 1.3343\n",
      "Epoch: 336/1000\n",
      "Training: Loss: 1.3835\n",
      "Epoch: 337/1000\n",
      "Training: Loss: 1.4396\n",
      "Epoch: 338/1000\n",
      "Training: Loss: 1.4233\n",
      "Epoch: 339/1000\n",
      "Training: Loss: 1.4092\n",
      "Epoch: 340/1000\n",
      "Training: Loss: 1.4958\n",
      "Epoch: 341/1000\n",
      "Training: Loss: 1.4231\n",
      "Epoch: 342/1000\n",
      "Training: Loss: 1.3358\n",
      "Epoch: 343/1000\n",
      "Training: Loss: 1.3812\n",
      "Epoch: 344/1000\n",
      "Training: Loss: 1.3606\n",
      "Epoch: 345/1000\n",
      "Training: Loss: 1.5180\n",
      "Epoch: 346/1000\n",
      "Training: Loss: 1.4566\n",
      "Epoch: 347/1000\n",
      "Training: Loss: 1.4434\n",
      "Epoch: 348/1000\n",
      "Training: Loss: 1.3494\n",
      "Epoch: 349/1000\n",
      "Training: Loss: 1.4304\n",
      "Epoch: 350/1000\n",
      "Training: Loss: 1.3554\n",
      "Epoch: 351/1000\n",
      "Training: Loss: 1.4826\n",
      "Epoch: 352/1000\n",
      "Training: Loss: 1.2779\n",
      "Epoch: 353/1000\n",
      "Training: Loss: 1.3837\n",
      "Epoch: 354/1000\n",
      "Training: Loss: 1.4369\n",
      "Epoch: 355/1000\n",
      "Training: Loss: 1.3255\n",
      "Epoch: 356/1000\n",
      "Training: Loss: 1.3863\n",
      "Epoch: 357/1000\n",
      "Training: Loss: 1.4978\n",
      "Epoch: 358/1000\n",
      "Training: Loss: 1.3514\n",
      "Epoch: 359/1000\n",
      "Training: Loss: 1.3563\n",
      "Epoch: 360/1000\n",
      "Training: Loss: 1.3616\n",
      "Epoch: 361/1000\n",
      "Training: Loss: 1.4453\n",
      "Epoch: 362/1000\n",
      "Training: Loss: 1.5113\n",
      "Epoch: 363/1000\n",
      "Training: Loss: 1.4540\n",
      "Epoch: 364/1000\n",
      "Training: Loss: 1.3610\n",
      "Epoch: 365/1000\n",
      "Training: Loss: 1.3795\n",
      "Epoch: 366/1000\n",
      "Training: Loss: 1.4154\n",
      "Epoch: 367/1000\n",
      "Training: Loss: 1.3569\n",
      "Epoch: 368/1000\n",
      "Training: Loss: 1.4502\n",
      "Epoch: 369/1000\n",
      "Training: Loss: 1.5074\n",
      "Epoch: 370/1000\n",
      "Training: Loss: 1.4655\n",
      "Epoch: 371/1000\n",
      "Training: Loss: 1.4529\n",
      "Epoch: 372/1000\n",
      "Training: Loss: 1.4429\n",
      "Epoch: 373/1000\n",
      "Training: Loss: 1.4451\n",
      "Epoch: 374/1000\n",
      "Training: Loss: 1.4273\n",
      "Epoch: 375/1000\n",
      "Training: Loss: 1.4124\n",
      "Epoch: 376/1000\n",
      "Training: Loss: 1.4481\n",
      "Epoch: 377/1000\n",
      "Training: Loss: 1.4925\n",
      "Epoch: 378/1000\n",
      "Training: Loss: 1.3794\n",
      "Epoch: 379/1000\n",
      "Training: Loss: 1.4417\n",
      "Epoch: 380/1000\n",
      "Training: Loss: 1.4754\n",
      "Epoch: 381/1000\n",
      "Training: Loss: 1.3932\n",
      "Epoch: 382/1000\n",
      "Training: Loss: 1.4183\n",
      "Epoch: 383/1000\n",
      "Training: Loss: 1.4112\n",
      "Epoch: 384/1000\n",
      "Training: Loss: 1.4149\n",
      "Epoch: 385/1000\n",
      "Training: Loss: 1.4516\n",
      "Epoch: 386/1000\n",
      "Training: Loss: 1.3987\n",
      "Epoch: 387/1000\n",
      "Training: Loss: 1.4141\n",
      "Epoch: 388/1000\n",
      "Training: Loss: 1.4719\n",
      "Epoch: 389/1000\n",
      "Training: Loss: 1.4505\n",
      "Epoch: 390/1000\n",
      "Training: Loss: 1.3278\n",
      "Epoch: 391/1000\n",
      "Training: Loss: 1.5224\n",
      "Epoch: 392/1000\n",
      "Training: Loss: 1.3625\n",
      "Epoch: 393/1000\n",
      "Training: Loss: 1.3755\n",
      "Epoch: 394/1000\n",
      "Training: Loss: 1.4568\n",
      "Epoch: 395/1000\n",
      "Training: Loss: 1.3724\n",
      "Epoch: 396/1000\n",
      "Training: Loss: 1.3504\n",
      "Epoch: 397/1000\n",
      "Training: Loss: 1.4883\n",
      "Epoch: 398/1000\n",
      "Training: Loss: 1.4126\n",
      "Epoch: 399/1000\n",
      "Training: Loss: 1.4327\n",
      "Epoch: 400/1000\n",
      "Training: Loss: 1.3629\n",
      "Epoch: 401/1000\n",
      "Training: Loss: 1.4377\n",
      "Epoch: 402/1000\n",
      "Training: Loss: 1.4590\n",
      "Epoch: 403/1000\n",
      "Training: Loss: 1.4344\n",
      "Epoch: 404/1000\n",
      "Training: Loss: 1.4605\n",
      "Epoch: 405/1000\n",
      "Training: Loss: 1.4384\n",
      "Epoch: 406/1000\n",
      "Training: Loss: 1.4364\n",
      "Epoch: 407/1000\n",
      "Training: Loss: 1.4009\n",
      "Epoch: 408/1000\n",
      "Training: Loss: 1.3199\n",
      "Epoch: 409/1000\n",
      "Training: Loss: 1.3959\n",
      "Epoch: 410/1000\n",
      "Training: Loss: 1.4202\n",
      "Epoch: 411/1000\n",
      "Training: Loss: 1.4071\n",
      "Epoch: 412/1000\n",
      "Training: Loss: 1.4327\n",
      "Epoch: 413/1000\n",
      "Training: Loss: 1.4047\n",
      "Epoch: 414/1000\n",
      "Training: Loss: 1.3623\n",
      "Epoch: 415/1000\n",
      "Training: Loss: 1.3480\n",
      "Epoch: 416/1000\n",
      "Training: Loss: 1.3658\n",
      "Epoch: 417/1000\n",
      "Training: Loss: 1.4574\n",
      "Epoch: 418/1000\n",
      "Training: Loss: 1.4201\n",
      "Epoch: 419/1000\n",
      "Training: Loss: 1.4574\n",
      "Epoch: 420/1000\n",
      "Training: Loss: 1.4220\n",
      "Epoch: 421/1000\n",
      "Training: Loss: 1.3485\n",
      "Epoch: 422/1000\n",
      "Training: Loss: 1.3935\n",
      "Epoch: 423/1000\n",
      "Training: Loss: 1.4628\n",
      "Epoch: 424/1000\n",
      "Training: Loss: 1.4231\n",
      "Epoch: 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.3773\n",
      "Epoch: 426/1000\n",
      "Training: Loss: 1.4701\n",
      "Epoch: 427/1000\n",
      "Training: Loss: 1.3703\n",
      "Epoch: 428/1000\n",
      "Training: Loss: 1.4568\n",
      "Epoch: 429/1000\n",
      "Training: Loss: 1.3957\n",
      "Epoch: 430/1000\n",
      "Training: Loss: 1.4220\n",
      "Epoch: 431/1000\n",
      "Training: Loss: 1.4545\n",
      "Epoch: 432/1000\n",
      "Training: Loss: 1.4835\n",
      "Epoch: 433/1000\n",
      "Training: Loss: 1.5630\n",
      "Epoch: 434/1000\n",
      "Training: Loss: 1.5219\n",
      "Epoch: 435/1000\n",
      "Training: Loss: 1.3451\n",
      "Epoch: 436/1000\n",
      "Training: Loss: 1.4162\n",
      "Epoch: 437/1000\n",
      "Training: Loss: 1.3562\n",
      "Epoch: 438/1000\n",
      "Training: Loss: 1.3992\n",
      "Epoch: 439/1000\n",
      "Training: Loss: 1.4557\n",
      "Epoch: 440/1000\n",
      "Training: Loss: 1.4079\n",
      "Epoch: 441/1000\n",
      "Training: Loss: 1.4247\n",
      "Epoch: 442/1000\n",
      "Training: Loss: 1.5255\n",
      "Epoch: 443/1000\n",
      "Training: Loss: 1.4567\n",
      "Epoch: 444/1000\n",
      "Training: Loss: 1.4339\n",
      "Epoch: 445/1000\n",
      "Training: Loss: 1.3906\n",
      "Epoch: 446/1000\n",
      "Training: Loss: 1.3940\n",
      "Epoch: 447/1000\n",
      "Training: Loss: 1.4896\n",
      "Epoch: 448/1000\n",
      "Training: Loss: 1.4021\n",
      "Epoch: 449/1000\n",
      "Training: Loss: 1.3829\n",
      "Epoch: 450/1000\n",
      "Training: Loss: 1.4521\n",
      "Epoch: 451/1000\n",
      "Training: Loss: 1.4936\n",
      "Epoch: 452/1000\n",
      "Training: Loss: 1.4516\n",
      "Epoch: 453/1000\n",
      "Training: Loss: 1.4103\n",
      "Epoch: 454/1000\n",
      "Training: Loss: 1.3862\n",
      "Epoch: 455/1000\n",
      "Training: Loss: 1.4257\n",
      "Epoch: 456/1000\n",
      "Training: Loss: 1.4312\n",
      "Epoch: 457/1000\n",
      "Training: Loss: 1.4184\n",
      "Epoch: 458/1000\n",
      "Training: Loss: 1.4361\n",
      "Epoch: 459/1000\n",
      "Training: Loss: 1.3116\n",
      "Epoch: 460/1000\n",
      "Training: Loss: 1.4351\n",
      "Epoch: 461/1000\n",
      "Training: Loss: 1.4109\n",
      "Epoch: 462/1000\n",
      "Training: Loss: 1.4546\n",
      "Epoch: 463/1000\n",
      "Training: Loss: 1.4219\n",
      "Epoch: 464/1000\n",
      "Training: Loss: 1.3357\n",
      "Epoch: 465/1000\n",
      "Training: Loss: 1.3888\n",
      "Epoch: 466/1000\n",
      "Training: Loss: 1.4101\n",
      "Epoch: 467/1000\n",
      "Training: Loss: 1.5125\n",
      "Epoch: 468/1000\n",
      "Training: Loss: 1.4159\n",
      "Epoch: 469/1000\n",
      "Training: Loss: 1.3576\n",
      "Epoch: 470/1000\n",
      "Training: Loss: 1.4126\n",
      "Epoch: 471/1000\n",
      "Training: Loss: 1.4512\n",
      "Epoch: 472/1000\n",
      "Training: Loss: 1.4241\n",
      "Epoch: 473/1000\n",
      "Training: Loss: 1.3830\n",
      "Epoch: 474/1000\n",
      "Training: Loss: 1.3233\n",
      "Epoch: 475/1000\n",
      "Training: Loss: 1.4478\n",
      "Epoch: 476/1000\n",
      "Training: Loss: 1.4069\n",
      "Epoch: 477/1000\n",
      "Training: Loss: 1.4838\n",
      "Epoch: 478/1000\n",
      "Training: Loss: 1.3542\n",
      "Epoch: 479/1000\n",
      "Training: Loss: 1.3859\n",
      "Epoch: 480/1000\n",
      "Training: Loss: 1.3684\n",
      "Epoch: 481/1000\n",
      "Training: Loss: 1.3623\n",
      "Epoch: 482/1000\n",
      "Training: Loss: 1.5164\n",
      "Epoch: 483/1000\n",
      "Training: Loss: 1.3855\n",
      "Epoch: 484/1000\n",
      "Training: Loss: 1.4392\n",
      "Epoch: 485/1000\n",
      "Training: Loss: 1.3623\n",
      "Epoch: 486/1000\n",
      "Training: Loss: 1.4506\n",
      "Epoch: 487/1000\n",
      "Training: Loss: 1.3381\n",
      "Epoch: 488/1000\n",
      "Training: Loss: 1.5129\n",
      "Epoch: 489/1000\n",
      "Training: Loss: 1.3367\n",
      "Epoch: 490/1000\n",
      "Training: Loss: 1.4100\n",
      "Epoch: 491/1000\n",
      "Training: Loss: 1.4403\n",
      "Epoch: 492/1000\n",
      "Training: Loss: 1.3881\n",
      "Epoch: 493/1000\n",
      "Training: Loss: 1.3799\n",
      "Epoch: 494/1000\n",
      "Training: Loss: 1.3795\n",
      "Epoch: 495/1000\n",
      "Training: Loss: 1.3937\n",
      "Epoch: 496/1000\n",
      "Training: Loss: 1.3712\n",
      "Epoch: 497/1000\n",
      "Training: Loss: 1.4373\n",
      "Epoch: 498/1000\n",
      "Training: Loss: 1.4082\n",
      "Epoch: 499/1000\n",
      "Training: Loss: 1.4341\n",
      "Epoch: 500/1000\n",
      "Training: Loss: 1.4168\n",
      "Epoch: 501/1000\n",
      "Training: Loss: 1.3952\n",
      "Epoch: 502/1000\n",
      "Training: Loss: 1.3568\n",
      "Epoch: 503/1000\n",
      "Training: Loss: 1.3689\n",
      "Epoch: 504/1000\n",
      "Training: Loss: 1.4275\n",
      "Epoch: 505/1000\n",
      "Training: Loss: 1.4111\n",
      "Epoch: 506/1000\n",
      "Training: Loss: 1.5202\n",
      "Epoch: 507/1000\n",
      "Training: Loss: 1.3654\n",
      "Epoch: 508/1000\n",
      "Training: Loss: 1.4348\n",
      "Epoch: 509/1000\n",
      "Training: Loss: 1.3440\n",
      "Epoch: 510/1000\n",
      "Training: Loss: 1.3402\n",
      "Epoch: 511/1000\n",
      "Training: Loss: 1.4329\n",
      "Epoch: 512/1000\n",
      "Training: Loss: 1.3414\n",
      "Epoch: 513/1000\n",
      "Training: Loss: 1.4105\n",
      "Epoch: 514/1000\n",
      "Training: Loss: 1.3884\n",
      "Epoch: 515/1000\n",
      "Training: Loss: 1.3620\n",
      "Epoch: 516/1000\n",
      "Training: Loss: 1.3929\n",
      "Epoch: 517/1000\n",
      "Training: Loss: 1.4510\n",
      "Epoch: 518/1000\n",
      "Training: Loss: 1.4185\n",
      "Epoch: 519/1000\n",
      "Training: Loss: 1.4342\n",
      "Epoch: 520/1000\n",
      "Training: Loss: 1.4529\n",
      "Epoch: 521/1000\n",
      "Training: Loss: 1.5209\n",
      "Epoch: 522/1000\n",
      "Training: Loss: 1.3767\n",
      "Epoch: 523/1000\n",
      "Training: Loss: 1.3449\n",
      "Epoch: 524/1000\n",
      "Training: Loss: 1.3481\n",
      "Epoch: 525/1000\n",
      "Training: Loss: 1.4096\n",
      "Epoch: 526/1000\n",
      "Training: Loss: 1.3577\n",
      "Epoch: 527/1000\n",
      "Training: Loss: 1.5072\n",
      "Epoch: 528/1000\n",
      "Training: Loss: 1.4540\n",
      "Epoch: 529/1000\n",
      "Training: Loss: 1.3101\n",
      "Epoch: 530/1000\n",
      "Training: Loss: 1.4033\n",
      "Epoch: 531/1000\n",
      "Training: Loss: 1.4362\n",
      "Epoch: 532/1000\n",
      "Training: Loss: 1.4590\n",
      "Epoch: 533/1000\n",
      "Training: Loss: 1.3194\n",
      "Epoch: 534/1000\n",
      "Training: Loss: 1.4051\n",
      "Epoch: 535/1000\n",
      "Training: Loss: 1.3952\n",
      "Epoch: 536/1000\n",
      "Training: Loss: 1.4725\n",
      "Epoch: 537/1000\n",
      "Training: Loss: 1.4379\n",
      "Epoch: 538/1000\n",
      "Training: Loss: 1.4144\n",
      "Epoch: 539/1000\n",
      "Training: Loss: 1.4846\n",
      "Epoch: 540/1000\n",
      "Training: Loss: 1.4846\n",
      "Epoch: 541/1000\n",
      "Training: Loss: 1.4416\n",
      "Epoch: 542/1000\n",
      "Training: Loss: 1.3522\n",
      "Epoch: 543/1000\n",
      "Training: Loss: 1.4176\n",
      "Epoch: 544/1000\n",
      "Training: Loss: 1.4451\n",
      "Epoch: 545/1000\n",
      "Training: Loss: 1.4045\n",
      "Epoch: 546/1000\n",
      "Training: Loss: 1.4844\n",
      "Epoch: 547/1000\n",
      "Training: Loss: 1.2781\n",
      "Epoch: 548/1000\n",
      "Training: Loss: 1.4873\n",
      "Epoch: 549/1000\n",
      "Training: Loss: 1.4227\n",
      "Epoch: 550/1000\n",
      "Training: Loss: 1.4350\n",
      "Epoch: 551/1000\n",
      "Training: Loss: 1.3557\n",
      "Epoch: 552/1000\n",
      "Training: Loss: 1.4998\n",
      "Epoch: 553/1000\n",
      "Training: Loss: 1.3769\n",
      "Epoch: 554/1000\n",
      "Training: Loss: 1.3308\n",
      "Epoch: 555/1000\n",
      "Training: Loss: 1.3785\n",
      "Epoch: 556/1000\n",
      "Training: Loss: 1.3859\n",
      "Epoch: 557/1000\n",
      "Training: Loss: 1.3929\n",
      "Epoch: 558/1000\n",
      "Training: Loss: 1.4650\n",
      "Epoch: 559/1000\n",
      "Training: Loss: 1.4836\n",
      "Epoch: 560/1000\n",
      "Training: Loss: 1.5197\n",
      "Epoch: 561/1000\n",
      "Training: Loss: 1.4746\n",
      "Epoch: 562/1000\n",
      "Training: Loss: 1.4229\n",
      "Epoch: 563/1000\n",
      "Training: Loss: 1.3560\n",
      "Epoch: 564/1000\n",
      "Training: Loss: 1.4491\n",
      "Epoch: 565/1000\n",
      "Training: Loss: 1.4724\n",
      "Epoch: 566/1000\n",
      "Training: Loss: 1.4622\n",
      "Epoch: 567/1000\n",
      "Training: Loss: 1.3866\n",
      "Epoch: 568/1000\n",
      "Training: Loss: 1.4768\n",
      "Epoch: 569/1000\n",
      "Training: Loss: 1.3631\n",
      "Epoch: 570/1000\n",
      "Training: Loss: 1.3099\n",
      "Epoch: 571/1000\n",
      "Training: Loss: 1.3584\n",
      "Epoch: 572/1000\n",
      "Training: Loss: 1.3525\n",
      "Epoch: 573/1000\n",
      "Training: Loss: 1.3924\n",
      "Epoch: 574/1000\n",
      "Training: Loss: 1.3902\n",
      "Epoch: 575/1000\n",
      "Training: Loss: 1.4147\n",
      "Epoch: 576/1000\n",
      "Training: Loss: 1.4808\n",
      "Epoch: 577/1000\n",
      "Training: Loss: 1.3602\n",
      "Epoch: 578/1000\n",
      "Training: Loss: 1.4561\n",
      "Epoch: 579/1000\n",
      "Training: Loss: 1.4433\n",
      "Epoch: 580/1000\n",
      "Training: Loss: 1.3901\n",
      "Epoch: 581/1000\n",
      "Training: Loss: 1.3935\n",
      "Epoch: 582/1000\n",
      "Training: Loss: 1.3415\n",
      "Epoch: 583/1000\n",
      "Training: Loss: 1.3666\n",
      "Epoch: 584/1000\n",
      "Training: Loss: 1.2582\n",
      "Epoch: 585/1000\n",
      "Training: Loss: 1.4058\n",
      "Epoch: 586/1000\n",
      "Training: Loss: 1.3773\n",
      "Epoch: 587/1000\n",
      "Training: Loss: 1.4357\n",
      "Epoch: 588/1000\n",
      "Training: Loss: 1.3952\n",
      "Epoch: 589/1000\n",
      "Training: Loss: 1.3251\n",
      "Epoch: 590/1000\n",
      "Training: Loss: 1.4195\n",
      "Epoch: 591/1000\n",
      "Training: Loss: 1.3255\n",
      "Epoch: 592/1000\n",
      "Training: Loss: 1.4477\n",
      "Epoch: 593/1000\n",
      "Training: Loss: 1.4204\n",
      "Epoch: 594/1000\n",
      "Training: Loss: 1.4420\n",
      "Epoch: 595/1000\n",
      "Training: Loss: 1.4620\n",
      "Epoch: 596/1000\n",
      "Training: Loss: 1.3872\n",
      "Epoch: 597/1000\n",
      "Training: Loss: 1.3310\n",
      "Epoch: 598/1000\n",
      "Training: Loss: 1.3309\n",
      "Epoch: 599/1000\n",
      "Training: Loss: 1.3850\n",
      "Epoch: 600/1000\n",
      "Training: Loss: 1.3282\n",
      "Epoch: 601/1000\n",
      "Training: Loss: 1.4997\n",
      "Epoch: 602/1000\n",
      "Training: Loss: 1.4526\n",
      "Epoch: 603/1000\n",
      "Training: Loss: 1.3426\n",
      "Epoch: 604/1000\n",
      "Training: Loss: 1.3753\n",
      "Epoch: 605/1000\n",
      "Training: Loss: 1.3002\n",
      "Epoch: 606/1000\n",
      "Training: Loss: 1.3708\n",
      "Epoch: 607/1000\n",
      "Training: Loss: 1.4678\n",
      "Epoch: 608/1000\n",
      "Training: Loss: 1.3850\n",
      "Epoch: 609/1000\n",
      "Training: Loss: 1.3818\n",
      "Epoch: 610/1000\n",
      "Training: Loss: 1.4263\n",
      "Epoch: 611/1000\n",
      "Training: Loss: 1.4280\n",
      "Epoch: 612/1000\n",
      "Training: Loss: 1.4497\n",
      "Epoch: 613/1000\n",
      "Training: Loss: 1.5198\n",
      "Epoch: 614/1000\n",
      "Training: Loss: 1.4713\n",
      "Epoch: 615/1000\n",
      "Training: Loss: 1.3159\n",
      "Epoch: 616/1000\n",
      "Training: Loss: 1.3612\n",
      "Epoch: 617/1000\n",
      "Training: Loss: 1.4364\n",
      "Epoch: 618/1000\n",
      "Training: Loss: 1.4575\n",
      "Epoch: 619/1000\n",
      "Training: Loss: 1.4396\n",
      "Epoch: 620/1000\n",
      "Training: Loss: 1.3376\n",
      "Epoch: 621/1000\n",
      "Training: Loss: 1.4253\n",
      "Epoch: 622/1000\n",
      "Training: Loss: 1.4354\n",
      "Epoch: 623/1000\n",
      "Training: Loss: 1.3531\n",
      "Epoch: 624/1000\n",
      "Training: Loss: 1.3912\n",
      "Epoch: 625/1000\n",
      "Training: Loss: 1.3590\n",
      "Epoch: 626/1000\n",
      "Training: Loss: 1.4101\n",
      "Epoch: 627/1000\n",
      "Training: Loss: 1.3473\n",
      "Epoch: 628/1000\n",
      "Training: Loss: 1.3130\n",
      "Epoch: 629/1000\n",
      "Training: Loss: 1.4367\n",
      "Epoch: 630/1000\n",
      "Training: Loss: 1.4369\n",
      "Epoch: 631/1000\n",
      "Training: Loss: 1.5098\n",
      "Epoch: 632/1000\n",
      "Training: Loss: 1.3037\n",
      "Epoch: 633/1000\n",
      "Training: Loss: 1.3770\n",
      "Epoch: 634/1000\n",
      "Training: Loss: 1.3594\n",
      "Epoch: 635/1000\n",
      "Training: Loss: 1.3846\n",
      "Epoch: 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.4157\n",
      "Epoch: 637/1000\n",
      "Training: Loss: 1.4079\n",
      "Epoch: 638/1000\n",
      "Training: Loss: 1.3708\n",
      "Epoch: 639/1000\n",
      "Training: Loss: 1.4001\n",
      "Epoch: 640/1000\n",
      "Training: Loss: 1.4706\n",
      "Epoch: 641/1000\n",
      "Training: Loss: 1.4091\n",
      "Epoch: 642/1000\n",
      "Training: Loss: 1.3906\n",
      "Epoch: 643/1000\n",
      "Training: Loss: 1.4931\n",
      "Epoch: 644/1000\n",
      "Training: Loss: 1.4062\n",
      "Epoch: 645/1000\n",
      "Training: Loss: 1.3855\n",
      "Epoch: 646/1000\n",
      "Training: Loss: 1.3862\n",
      "Epoch: 647/1000\n",
      "Training: Loss: 1.4323\n",
      "Epoch: 648/1000\n",
      "Training: Loss: 1.4933\n",
      "Epoch: 649/1000\n",
      "Training: Loss: 1.4741\n",
      "Epoch: 650/1000\n",
      "Training: Loss: 1.4920\n",
      "Epoch: 651/1000\n",
      "Training: Loss: 1.3616\n",
      "Epoch: 652/1000\n",
      "Training: Loss: 1.3293\n",
      "Epoch: 653/1000\n",
      "Training: Loss: 1.4876\n",
      "Epoch: 654/1000\n",
      "Training: Loss: 1.3534\n",
      "Epoch: 655/1000\n",
      "Training: Loss: 1.4745\n",
      "Epoch: 656/1000\n",
      "Training: Loss: 1.4023\n",
      "Epoch: 657/1000\n",
      "Training: Loss: 1.4314\n",
      "Epoch: 658/1000\n",
      "Training: Loss: 1.3820\n",
      "Epoch: 659/1000\n",
      "Training: Loss: 1.4571\n",
      "Epoch: 660/1000\n",
      "Training: Loss: 1.2534\n",
      "Epoch: 661/1000\n",
      "Training: Loss: 1.3694\n",
      "Epoch: 662/1000\n",
      "Training: Loss: 1.4393\n",
      "Epoch: 663/1000\n",
      "Training: Loss: 1.4207\n",
      "Epoch: 664/1000\n",
      "Training: Loss: 1.3719\n",
      "Epoch: 665/1000\n",
      "Training: Loss: 1.3845\n",
      "Epoch: 666/1000\n",
      "Training: Loss: 1.3760\n",
      "Epoch: 667/1000\n",
      "Training: Loss: 1.3160\n",
      "Epoch: 668/1000\n",
      "Training: Loss: 1.4235\n",
      "Epoch: 669/1000\n",
      "Training: Loss: 1.4100\n",
      "Epoch: 670/1000\n",
      "Training: Loss: 1.4636\n",
      "Epoch: 671/1000\n",
      "Training: Loss: 1.4266\n",
      "Epoch: 672/1000\n",
      "Training: Loss: 1.3094\n",
      "Epoch: 673/1000\n",
      "Training: Loss: 1.4084\n",
      "Epoch: 674/1000\n",
      "Training: Loss: 1.3737\n",
      "Epoch: 675/1000\n",
      "Training: Loss: 1.3281\n",
      "Epoch: 676/1000\n",
      "Training: Loss: 1.3045\n",
      "Epoch: 677/1000\n",
      "Training: Loss: 1.4623\n",
      "Epoch: 678/1000\n",
      "Training: Loss: 1.4644\n",
      "Epoch: 679/1000\n",
      "Training: Loss: 1.4190\n",
      "Epoch: 680/1000\n",
      "Training: Loss: 1.4082\n",
      "Epoch: 681/1000\n",
      "Training: Loss: 1.4260\n",
      "Epoch: 682/1000\n",
      "Training: Loss: 1.4018\n",
      "Epoch: 683/1000\n",
      "Training: Loss: 1.4313\n",
      "Epoch: 684/1000\n",
      "Training: Loss: 1.4072\n",
      "Epoch: 685/1000\n",
      "Training: Loss: 1.3832\n",
      "Epoch: 686/1000\n",
      "Training: Loss: 1.3986\n",
      "Epoch: 687/1000\n",
      "Training: Loss: 1.3795\n",
      "Epoch: 688/1000\n",
      "Training: Loss: 1.4081\n",
      "Epoch: 689/1000\n",
      "Training: Loss: 1.4555\n",
      "Epoch: 690/1000\n",
      "Training: Loss: 1.3963\n",
      "Epoch: 691/1000\n",
      "Training: Loss: 1.4657\n",
      "Epoch: 692/1000\n",
      "Training: Loss: 1.4247\n",
      "Epoch: 693/1000\n",
      "Training: Loss: 1.4020\n",
      "Epoch: 694/1000\n",
      "Training: Loss: 1.3295\n",
      "Epoch: 695/1000\n",
      "Training: Loss: 1.3875\n",
      "Epoch: 696/1000\n",
      "Training: Loss: 1.3813\n",
      "Epoch: 697/1000\n",
      "Training: Loss: 1.3123\n",
      "Epoch: 698/1000\n",
      "Training: Loss: 1.4802\n",
      "Epoch: 699/1000\n",
      "Training: Loss: 1.3496\n",
      "Epoch: 700/1000\n",
      "Training: Loss: 1.4664\n",
      "Epoch: 701/1000\n",
      "Training: Loss: 1.3662\n",
      "Epoch: 702/1000\n",
      "Training: Loss: 1.3385\n",
      "Epoch: 703/1000\n",
      "Training: Loss: 1.4493\n",
      "Epoch: 704/1000\n",
      "Training: Loss: 1.3893\n",
      "Epoch: 705/1000\n",
      "Training: Loss: 1.3829\n",
      "Epoch: 706/1000\n",
      "Training: Loss: 1.4400\n",
      "Epoch: 707/1000\n",
      "Training: Loss: 1.3294\n",
      "Epoch: 708/1000\n",
      "Training: Loss: 1.3537\n",
      "Epoch: 709/1000\n",
      "Training: Loss: 1.4859\n",
      "Epoch: 710/1000\n",
      "Training: Loss: 1.3225\n",
      "Epoch: 711/1000\n",
      "Training: Loss: 1.4065\n",
      "Epoch: 712/1000\n",
      "Training: Loss: 1.3424\n",
      "Epoch: 713/1000\n",
      "Training: Loss: 1.3558\n",
      "Epoch: 714/1000\n",
      "Training: Loss: 1.5009\n",
      "Epoch: 715/1000\n",
      "Training: Loss: 1.3763\n",
      "Epoch: 716/1000\n",
      "Training: Loss: 1.3874\n",
      "Epoch: 717/1000\n",
      "Training: Loss: 1.4295\n",
      "Epoch: 718/1000\n",
      "Training: Loss: 1.3934\n",
      "Epoch: 719/1000\n",
      "Training: Loss: 1.4546\n",
      "Epoch: 720/1000\n",
      "Training: Loss: 1.4361\n",
      "Epoch: 721/1000\n",
      "Training: Loss: 1.3785\n",
      "Epoch: 722/1000\n",
      "Training: Loss: 1.3792\n",
      "Epoch: 723/1000\n",
      "Training: Loss: 1.3613\n",
      "Epoch: 724/1000\n",
      "Training: Loss: 1.3759\n",
      "Epoch: 725/1000\n",
      "Training: Loss: 1.3436\n",
      "Epoch: 726/1000\n",
      "Training: Loss: 1.3823\n",
      "Epoch: 727/1000\n",
      "Training: Loss: 1.3494\n",
      "Epoch: 728/1000\n",
      "Training: Loss: 1.4879\n",
      "Epoch: 729/1000\n",
      "Training: Loss: 1.2961\n",
      "Epoch: 730/1000\n",
      "Training: Loss: 1.4908\n",
      "Epoch: 731/1000\n",
      "Training: Loss: 1.4227\n",
      "Epoch: 732/1000\n",
      "Training: Loss: 1.4626\n",
      "Epoch: 733/1000\n",
      "Training: Loss: 1.4340\n",
      "Epoch: 734/1000\n",
      "Training: Loss: 1.3558\n",
      "Epoch: 735/1000\n",
      "Training: Loss: 1.3393\n",
      "Epoch: 736/1000\n",
      "Training: Loss: 1.5033\n",
      "Epoch: 737/1000\n",
      "Training: Loss: 1.3941\n",
      "Epoch: 738/1000\n",
      "Training: Loss: 1.4481\n",
      "Epoch: 739/1000\n",
      "Training: Loss: 1.4781\n",
      "Epoch: 740/1000\n",
      "Training: Loss: 1.4485\n",
      "Epoch: 741/1000\n",
      "Training: Loss: 1.3830\n",
      "Epoch: 742/1000\n",
      "Training: Loss: 1.4400\n",
      "Epoch: 743/1000\n",
      "Training: Loss: 1.4646\n",
      "Epoch: 744/1000\n",
      "Training: Loss: 1.3637\n",
      "Epoch: 745/1000\n",
      "Training: Loss: 1.4094\n",
      "Epoch: 746/1000\n",
      "Training: Loss: 1.4078\n",
      "Epoch: 747/1000\n",
      "Training: Loss: 1.4316\n",
      "Epoch: 748/1000\n",
      "Training: Loss: 1.3205\n",
      "Epoch: 749/1000\n",
      "Training: Loss: 1.3411\n",
      "Epoch: 750/1000\n",
      "Training: Loss: 1.4230\n",
      "Epoch: 751/1000\n",
      "Training: Loss: 1.4778\n",
      "Epoch: 752/1000\n",
      "Training: Loss: 1.3622\n",
      "Epoch: 753/1000\n",
      "Training: Loss: 1.4224\n",
      "Epoch: 754/1000\n",
      "Training: Loss: 1.3768\n",
      "Epoch: 755/1000\n",
      "Training: Loss: 1.3817\n",
      "Epoch: 756/1000\n",
      "Training: Loss: 1.3245\n",
      "Epoch: 757/1000\n",
      "Training: Loss: 1.2776\n",
      "Epoch: 758/1000\n",
      "Training: Loss: 1.4069\n",
      "Epoch: 759/1000\n",
      "Training: Loss: 1.4330\n",
      "Epoch: 760/1000\n",
      "Training: Loss: 1.4064\n",
      "Epoch: 761/1000\n",
      "Training: Loss: 1.4045\n",
      "Epoch: 762/1000\n",
      "Training: Loss: 1.3418\n",
      "Epoch: 763/1000\n",
      "Training: Loss: 1.3441\n",
      "Epoch: 764/1000\n",
      "Training: Loss: 1.3413\n",
      "Epoch: 765/1000\n",
      "Training: Loss: 1.3516\n",
      "Epoch: 766/1000\n",
      "Training: Loss: 1.4884\n",
      "Epoch: 767/1000\n",
      "Training: Loss: 1.4058\n",
      "Epoch: 768/1000\n",
      "Training: Loss: 1.3973\n",
      "Epoch: 769/1000\n",
      "Training: Loss: 1.3563\n",
      "Epoch: 770/1000\n",
      "Training: Loss: 1.4298\n",
      "Epoch: 771/1000\n",
      "Training: Loss: 1.3209\n",
      "Epoch: 772/1000\n",
      "Training: Loss: 1.3841\n",
      "Epoch: 773/1000\n",
      "Training: Loss: 1.4029\n",
      "Epoch: 774/1000\n",
      "Training: Loss: 1.3709\n",
      "Epoch: 775/1000\n",
      "Training: Loss: 1.4943\n",
      "Epoch: 776/1000\n",
      "Training: Loss: 1.3682\n",
      "Epoch: 777/1000\n",
      "Training: Loss: 1.4026\n",
      "Epoch: 778/1000\n",
      "Training: Loss: 1.4807\n",
      "Epoch: 779/1000\n",
      "Training: Loss: 1.4870\n",
      "Epoch: 780/1000\n",
      "Training: Loss: 1.3562\n",
      "Epoch: 781/1000\n",
      "Training: Loss: 1.4022\n",
      "Epoch: 782/1000\n",
      "Training: Loss: 1.3318\n",
      "Epoch: 783/1000\n",
      "Training: Loss: 1.4368\n",
      "Epoch: 784/1000\n",
      "Training: Loss: 1.3200\n",
      "Epoch: 785/1000\n",
      "Training: Loss: 1.4579\n",
      "Epoch: 786/1000\n",
      "Training: Loss: 1.4758\n",
      "Epoch: 787/1000\n",
      "Training: Loss: 1.3679\n",
      "Epoch: 788/1000\n",
      "Training: Loss: 1.3625\n",
      "Epoch: 789/1000\n",
      "Training: Loss: 1.4470\n",
      "Epoch: 790/1000\n",
      "Training: Loss: 1.3607\n",
      "Epoch: 791/1000\n",
      "Training: Loss: 1.4739\n",
      "Epoch: 792/1000\n",
      "Training: Loss: 1.3601\n",
      "Epoch: 793/1000\n",
      "Training: Loss: 1.3888\n",
      "Epoch: 794/1000\n",
      "Training: Loss: 1.3569\n",
      "Epoch: 795/1000\n",
      "Training: Loss: 1.3399\n",
      "Epoch: 796/1000\n",
      "Training: Loss: 1.4362\n",
      "Epoch: 797/1000\n",
      "Training: Loss: 1.4607\n",
      "Epoch: 798/1000\n",
      "Training: Loss: 1.3710\n",
      "Epoch: 799/1000\n",
      "Training: Loss: 1.3729\n",
      "Epoch: 800/1000\n",
      "Training: Loss: 1.3653\n",
      "Epoch: 801/1000\n",
      "Training: Loss: 1.4458\n",
      "Epoch: 802/1000\n",
      "Training: Loss: 1.4513\n",
      "Epoch: 803/1000\n",
      "Training: Loss: 1.4282\n",
      "Epoch: 804/1000\n",
      "Training: Loss: 1.4022\n",
      "Epoch: 805/1000\n",
      "Training: Loss: 1.3025\n",
      "Epoch: 806/1000\n",
      "Training: Loss: 1.3761\n",
      "Epoch: 807/1000\n",
      "Training: Loss: 1.5107\n",
      "Epoch: 808/1000\n",
      "Training: Loss: 1.3799\n",
      "Epoch: 809/1000\n",
      "Training: Loss: 1.4432\n",
      "Epoch: 810/1000\n",
      "Training: Loss: 1.4188\n",
      "Epoch: 811/1000\n",
      "Training: Loss: 1.4650\n",
      "Epoch: 812/1000\n",
      "Training: Loss: 1.4355\n",
      "Epoch: 813/1000\n",
      "Training: Loss: 1.4629\n",
      "Epoch: 814/1000\n",
      "Training: Loss: 1.4361\n",
      "Epoch: 815/1000\n",
      "Training: Loss: 1.3990\n",
      "Epoch: 816/1000\n",
      "Training: Loss: 1.3597\n",
      "Epoch: 817/1000\n",
      "Training: Loss: 1.4260\n",
      "Epoch: 818/1000\n",
      "Training: Loss: 1.4448\n",
      "Epoch: 819/1000\n",
      "Training: Loss: 1.4571\n",
      "Epoch: 820/1000\n",
      "Training: Loss: 1.3289\n",
      "Epoch: 821/1000\n",
      "Training: Loss: 1.3822\n",
      "Epoch: 822/1000\n",
      "Training: Loss: 1.3933\n",
      "Epoch: 823/1000\n",
      "Training: Loss: 1.4206\n",
      "Epoch: 824/1000\n",
      "Training: Loss: 1.4924\n",
      "Epoch: 825/1000\n",
      "Training: Loss: 1.4309\n",
      "Epoch: 826/1000\n",
      "Training: Loss: 1.3520\n",
      "Epoch: 827/1000\n",
      "Training: Loss: 1.4013\n",
      "Epoch: 828/1000\n",
      "Training: Loss: 1.4601\n",
      "Epoch: 829/1000\n",
      "Training: Loss: 1.3476\n",
      "Epoch: 830/1000\n",
      "Training: Loss: 1.3936\n",
      "Epoch: 831/1000\n",
      "Training: Loss: 1.4185\n",
      "Epoch: 832/1000\n",
      "Training: Loss: 1.4364\n",
      "Epoch: 833/1000\n",
      "Training: Loss: 1.4918\n",
      "Epoch: 834/1000\n",
      "Training: Loss: 1.3960\n",
      "Epoch: 835/1000\n",
      "Training: Loss: 1.3823\n",
      "Epoch: 836/1000\n",
      "Training: Loss: 1.4451\n",
      "Epoch: 837/1000\n",
      "Training: Loss: 1.4229\n",
      "Epoch: 838/1000\n",
      "Training: Loss: 1.5025\n",
      "Epoch: 839/1000\n",
      "Training: Loss: 1.4423\n",
      "Epoch: 840/1000\n",
      "Training: Loss: 1.3405\n",
      "Epoch: 841/1000\n",
      "Training: Loss: 1.4815\n",
      "Epoch: 842/1000\n",
      "Training: Loss: 1.4417\n",
      "Epoch: 843/1000\n",
      "Training: Loss: 1.3993\n",
      "Epoch: 844/1000\n",
      "Training: Loss: 1.2397\n",
      "Epoch: 845/1000\n",
      "Training: Loss: 1.3463\n",
      "Epoch: 846/1000\n",
      "Training: Loss: 1.3582\n",
      "Epoch: 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.4594\n",
      "Epoch: 848/1000\n",
      "Training: Loss: 1.4054\n",
      "Epoch: 849/1000\n",
      "Training: Loss: 1.3050\n",
      "Epoch: 850/1000\n",
      "Training: Loss: 1.4157\n",
      "Epoch: 851/1000\n",
      "Training: Loss: 1.3618\n",
      "Epoch: 852/1000\n",
      "Training: Loss: 1.4139\n",
      "Epoch: 853/1000\n",
      "Training: Loss: 1.3195\n",
      "Epoch: 854/1000\n",
      "Training: Loss: 1.4946\n",
      "Epoch: 855/1000\n",
      "Training: Loss: 1.3562\n",
      "Epoch: 856/1000\n",
      "Training: Loss: 1.3468\n",
      "Epoch: 857/1000\n",
      "Training: Loss: 1.2890\n",
      "Epoch: 858/1000\n",
      "Training: Loss: 1.4525\n",
      "Epoch: 859/1000\n",
      "Training: Loss: 1.4328\n",
      "Epoch: 860/1000\n",
      "Training: Loss: 1.3868\n",
      "Epoch: 861/1000\n",
      "Training: Loss: 1.4218\n",
      "Epoch: 862/1000\n",
      "Training: Loss: 1.4136\n",
      "Epoch: 863/1000\n",
      "Training: Loss: 1.3573\n",
      "Epoch: 864/1000\n",
      "Training: Loss: 1.3799\n",
      "Epoch: 865/1000\n",
      "Training: Loss: 1.4150\n",
      "Epoch: 866/1000\n",
      "Training: Loss: 1.4277\n",
      "Epoch: 867/1000\n",
      "Training: Loss: 1.3859\n",
      "Epoch: 868/1000\n",
      "Training: Loss: 1.4135\n",
      "Epoch: 869/1000\n",
      "Training: Loss: 1.2959\n",
      "Epoch: 870/1000\n",
      "Training: Loss: 1.4077\n",
      "Epoch: 871/1000\n",
      "Training: Loss: 1.3953\n",
      "Epoch: 872/1000\n",
      "Training: Loss: 1.3115\n",
      "Epoch: 873/1000\n",
      "Training: Loss: 1.4317\n",
      "Epoch: 874/1000\n",
      "Training: Loss: 1.3719\n",
      "Epoch: 875/1000\n",
      "Training: Loss: 1.3401\n",
      "Epoch: 876/1000\n",
      "Training: Loss: 1.4475\n",
      "Epoch: 877/1000\n",
      "Training: Loss: 1.4654\n",
      "Epoch: 878/1000\n",
      "Training: Loss: 1.3722\n",
      "Epoch: 879/1000\n",
      "Training: Loss: 1.4737\n",
      "Epoch: 880/1000\n",
      "Training: Loss: 1.2726\n",
      "Epoch: 881/1000\n",
      "Training: Loss: 1.3951\n",
      "Epoch: 882/1000\n",
      "Training: Loss: 1.4158\n",
      "Epoch: 883/1000\n",
      "Training: Loss: 1.4076\n",
      "Epoch: 884/1000\n",
      "Training: Loss: 1.3193\n",
      "Epoch: 885/1000\n",
      "Training: Loss: 1.4561\n",
      "Epoch: 886/1000\n",
      "Training: Loss: 1.3722\n",
      "Epoch: 887/1000\n",
      "Training: Loss: 1.4488\n",
      "Epoch: 888/1000\n",
      "Training: Loss: 1.4442\n",
      "Epoch: 889/1000\n",
      "Training: Loss: 1.3967\n",
      "Epoch: 890/1000\n",
      "Training: Loss: 1.4705\n",
      "Epoch: 891/1000\n",
      "Training: Loss: 1.4114\n",
      "Epoch: 892/1000\n",
      "Training: Loss: 1.4140\n",
      "Epoch: 893/1000\n",
      "Training: Loss: 1.3811\n",
      "Epoch: 894/1000\n",
      "Training: Loss: 1.5222\n",
      "Epoch: 895/1000\n",
      "Training: Loss: 1.3525\n",
      "Epoch: 896/1000\n",
      "Training: Loss: 1.4196\n",
      "Epoch: 897/1000\n",
      "Training: Loss: 1.3258\n",
      "Epoch: 898/1000\n",
      "Training: Loss: 1.4388\n",
      "Epoch: 899/1000\n",
      "Training: Loss: 1.4255\n",
      "Epoch: 900/1000\n",
      "Training: Loss: 1.5180\n",
      "Epoch: 901/1000\n",
      "Training: Loss: 1.3539\n",
      "Epoch: 902/1000\n",
      "Training: Loss: 1.4498\n",
      "Epoch: 903/1000\n",
      "Training: Loss: 1.4211\n",
      "Epoch: 904/1000\n",
      "Training: Loss: 1.3047\n",
      "Epoch: 905/1000\n",
      "Training: Loss: 1.3981\n",
      "Epoch: 906/1000\n",
      "Training: Loss: 1.4800\n",
      "Epoch: 907/1000\n",
      "Training: Loss: 1.4042\n",
      "Epoch: 908/1000\n",
      "Training: Loss: 1.3468\n",
      "Epoch: 909/1000\n",
      "Training: Loss: 1.4017\n",
      "Epoch: 910/1000\n",
      "Training: Loss: 1.4186\n",
      "Epoch: 911/1000\n",
      "Training: Loss: 1.4882\n",
      "Epoch: 912/1000\n",
      "Training: Loss: 1.3209\n",
      "Epoch: 913/1000\n",
      "Training: Loss: 1.4761\n",
      "Epoch: 914/1000\n",
      "Training: Loss: 1.3926\n",
      "Epoch: 915/1000\n",
      "Training: Loss: 1.3922\n",
      "Epoch: 916/1000\n",
      "Training: Loss: 1.3622\n",
      "Epoch: 917/1000\n",
      "Training: Loss: 1.4259\n",
      "Epoch: 918/1000\n",
      "Training: Loss: 1.4711\n",
      "Epoch: 919/1000\n",
      "Training: Loss: 1.4102\n",
      "Epoch: 920/1000\n",
      "Training: Loss: 1.5644\n",
      "Epoch: 921/1000\n",
      "Training: Loss: 1.4263\n",
      "Epoch: 922/1000\n",
      "Training: Loss: 1.3613\n",
      "Epoch: 923/1000\n",
      "Training: Loss: 1.3796\n",
      "Epoch: 924/1000\n",
      "Training: Loss: 1.5135\n",
      "Epoch: 925/1000\n",
      "Training: Loss: 1.4011\n",
      "Epoch: 926/1000\n",
      "Training: Loss: 1.4033\n",
      "Epoch: 927/1000\n",
      "Training: Loss: 1.3869\n",
      "Epoch: 928/1000\n",
      "Training: Loss: 1.3505\n",
      "Epoch: 929/1000\n",
      "Training: Loss: 1.3347\n",
      "Epoch: 930/1000\n",
      "Training: Loss: 1.4105\n",
      "Epoch: 931/1000\n",
      "Training: Loss: 1.4589\n",
      "Epoch: 932/1000\n",
      "Training: Loss: 1.4607\n",
      "Epoch: 933/1000\n",
      "Training: Loss: 1.4433\n",
      "Epoch: 934/1000\n",
      "Training: Loss: 1.4615\n",
      "Epoch: 935/1000\n",
      "Training: Loss: 1.3908\n",
      "Epoch: 936/1000\n",
      "Training: Loss: 1.3705\n",
      "Epoch: 937/1000\n",
      "Training: Loss: 1.3110\n",
      "Epoch: 938/1000\n",
      "Training: Loss: 1.3318\n",
      "Epoch: 939/1000\n",
      "Training: Loss: 1.4395\n",
      "Epoch: 940/1000\n",
      "Training: Loss: 1.4394\n",
      "Epoch: 941/1000\n",
      "Training: Loss: 1.3603\n",
      "Epoch: 942/1000\n",
      "Training: Loss: 1.4830\n",
      "Epoch: 943/1000\n",
      "Training: Loss: 1.4015\n",
      "Epoch: 944/1000\n",
      "Training: Loss: 1.3354\n",
      "Epoch: 945/1000\n",
      "Training: Loss: 1.4254\n",
      "Epoch: 946/1000\n",
      "Training: Loss: 1.3809\n",
      "Epoch: 947/1000\n",
      "Training: Loss: 1.3777\n",
      "Epoch: 948/1000\n",
      "Training: Loss: 1.4182\n",
      "Epoch: 949/1000\n",
      "Training: Loss: 1.4517\n",
      "Epoch: 950/1000\n",
      "Training: Loss: 1.4001\n",
      "Epoch: 951/1000\n",
      "Training: Loss: 1.4866\n",
      "Epoch: 952/1000\n",
      "Training: Loss: 1.4584\n",
      "Epoch: 953/1000\n",
      "Training: Loss: 1.5050\n",
      "Epoch: 954/1000\n",
      "Training: Loss: 1.4135\n",
      "Epoch: 955/1000\n",
      "Training: Loss: 1.4130\n",
      "Epoch: 956/1000\n",
      "Training: Loss: 1.4047\n",
      "Epoch: 957/1000\n",
      "Training: Loss: 1.4274\n",
      "Epoch: 958/1000\n",
      "Training: Loss: 1.3989\n",
      "Epoch: 959/1000\n",
      "Training: Loss: 1.3819\n",
      "Epoch: 960/1000\n",
      "Training: Loss: 1.3997\n",
      "Epoch: 961/1000\n",
      "Training: Loss: 1.4749\n",
      "Epoch: 962/1000\n",
      "Training: Loss: 1.4830\n",
      "Epoch: 963/1000\n",
      "Training: Loss: 1.3846\n",
      "Epoch: 964/1000\n",
      "Training: Loss: 1.5128\n",
      "Epoch: 965/1000\n",
      "Training: Loss: 1.4533\n",
      "Epoch: 966/1000\n",
      "Training: Loss: 1.3857\n",
      "Epoch: 967/1000\n",
      "Training: Loss: 1.3713\n",
      "Epoch: 968/1000\n",
      "Training: Loss: 1.4698\n",
      "Epoch: 969/1000\n",
      "Training: Loss: 1.4430\n",
      "Epoch: 970/1000\n",
      "Training: Loss: 1.4201\n",
      "Epoch: 971/1000\n",
      "Training: Loss: 1.4686\n",
      "Epoch: 972/1000\n",
      "Training: Loss: 1.3984\n",
      "Epoch: 973/1000\n",
      "Training: Loss: 1.3627\n",
      "Epoch: 974/1000\n",
      "Training: Loss: 1.2683\n",
      "Epoch: 975/1000\n",
      "Training: Loss: 1.3672\n",
      "Epoch: 976/1000\n",
      "Training: Loss: 1.3524\n",
      "Epoch: 977/1000\n",
      "Training: Loss: 1.4513\n",
      "Epoch: 978/1000\n",
      "Training: Loss: 1.4006\n",
      "Epoch: 979/1000\n",
      "Training: Loss: 1.4773\n",
      "Epoch: 980/1000\n",
      "Training: Loss: 1.4519\n",
      "Epoch: 981/1000\n",
      "Training: Loss: 1.4423\n",
      "Epoch: 982/1000\n",
      "Training: Loss: 1.4434\n",
      "Epoch: 983/1000\n",
      "Training: Loss: 1.3955\n",
      "Epoch: 984/1000\n",
      "Training: Loss: 1.4077\n",
      "Epoch: 985/1000\n",
      "Training: Loss: 1.3999\n",
      "Epoch: 986/1000\n",
      "Training: Loss: 1.4673\n",
      "Epoch: 987/1000\n",
      "Training: Loss: 1.4652\n",
      "Epoch: 988/1000\n",
      "Training: Loss: 1.5213\n",
      "Epoch: 989/1000\n",
      "Training: Loss: 1.4796\n",
      "Epoch: 990/1000\n",
      "Training: Loss: 1.3934\n",
      "Epoch: 991/1000\n",
      "Training: Loss: 1.3294\n",
      "Epoch: 992/1000\n",
      "Training: Loss: 1.4111\n",
      "Epoch: 993/1000\n",
      "Training: Loss: 1.4637\n",
      "Epoch: 994/1000\n",
      "Training: Loss: 1.4428\n",
      "Epoch: 995/1000\n",
      "Training: Loss: 1.4763\n",
      "Epoch: 996/1000\n",
      "Training: Loss: 1.4135\n",
      "Epoch: 997/1000\n",
      "Training: Loss: 1.4221\n",
      "Epoch: 998/1000\n",
      "Training: Loss: 1.3252\n",
      "Epoch: 999/1000\n",
      "Training: Loss: 1.4275\n",
      "Epoch: 1000/1000\n",
      "Training: Loss: 1.4330\n",
      "Epoch: 1001/1000\n",
      "Training: Loss: 1.3621\n",
      "Epoch: 1002/1000\n",
      "Training: Loss: 1.4166\n",
      "Epoch: 1003/1000\n",
      "Training: Loss: 1.4417\n",
      "Epoch: 1004/1000\n",
      "Training: Loss: 1.3882\n",
      "Epoch: 1005/1000\n",
      "Training: Loss: 1.4429\n",
      "Epoch: 1006/1000\n",
      "Training: Loss: 1.3735\n",
      "Epoch: 1007/1000\n",
      "Training: Loss: 1.3867\n",
      "Epoch: 1008/1000\n",
      "Training: Loss: 1.3328\n",
      "Epoch: 1009/1000\n",
      "Training: Loss: 1.3607\n",
      "Epoch: 1010/1000\n",
      "Training: Loss: 1.4162\n",
      "Epoch: 1011/1000\n",
      "Training: Loss: 1.3608\n",
      "Epoch: 1012/1000\n",
      "Training: Loss: 1.3580\n",
      "Epoch: 1013/1000\n",
      "Training: Loss: 1.4037\n",
      "Epoch: 1014/1000\n",
      "Training: Loss: 1.3872\n",
      "Epoch: 1015/1000\n",
      "Training: Loss: 1.4010\n",
      "Epoch: 1016/1000\n",
      "Training: Loss: 1.3909\n",
      "Epoch: 1017/1000\n",
      "Training: Loss: 1.3405\n",
      "Epoch: 1018/1000\n",
      "Training: Loss: 1.3553\n",
      "Epoch: 1019/1000\n",
      "Training: Loss: 1.3824\n",
      "Epoch: 1020/1000\n",
      "Training: Loss: 1.4199\n",
      "Epoch: 1021/1000\n",
      "Training: Loss: 1.4436\n",
      "Epoch: 1022/1000\n",
      "Training: Loss: 1.4431\n",
      "Epoch: 1023/1000\n",
      "Training: Loss: 1.3714\n",
      "Epoch: 1024/1000\n",
      "Training: Loss: 1.4652\n",
      "Epoch: 1025/1000\n",
      "Training: Loss: 1.4081\n",
      "Epoch: 1026/1000\n",
      "Training: Loss: 1.3562\n",
      "Epoch: 1027/1000\n",
      "Training: Loss: 1.3813\n",
      "Epoch: 1028/1000\n",
      "Training: Loss: 1.4093\n",
      "Epoch: 1029/1000\n",
      "Training: Loss: 1.4191\n",
      "Epoch: 1030/1000\n",
      "Training: Loss: 1.4112\n",
      "Epoch: 1031/1000\n",
      "Training: Loss: 1.3784\n",
      "Epoch: 1032/1000\n",
      "Training: Loss: 1.4820\n",
      "Epoch: 1033/1000\n",
      "Training: Loss: 1.4267\n",
      "Epoch: 1034/1000\n",
      "Training: Loss: 1.3858\n",
      "Epoch: 1035/1000\n",
      "Training: Loss: 1.3722\n",
      "Epoch: 1036/1000\n",
      "Training: Loss: 1.4883\n",
      "Epoch: 1037/1000\n",
      "Training: Loss: 1.4218\n",
      "Epoch: 1038/1000\n",
      "Training: Loss: 1.3179\n",
      "Epoch: 1039/1000\n",
      "Training: Loss: 1.3553\n",
      "Epoch: 1040/1000\n",
      "Training: Loss: 1.4230\n",
      "Epoch: 1041/1000\n",
      "Training: Loss: 1.4277\n",
      "Epoch: 1042/1000\n",
      "Training: Loss: 1.4097\n",
      "Epoch: 1043/1000\n",
      "Training: Loss: 1.3867\n",
      "Epoch: 1044/1000\n",
      "Training: Loss: 1.3789\n",
      "Epoch: 1045/1000\n",
      "Training: Loss: 1.3976\n",
      "Epoch: 1046/1000\n",
      "Training: Loss: 1.3620\n",
      "Epoch: 1047/1000\n",
      "Training: Loss: 1.4838\n",
      "Epoch: 1048/1000\n",
      "Training: Loss: 1.5556\n",
      "Epoch: 1049/1000\n",
      "Training: Loss: 1.5043\n",
      "Epoch: 1050/1000\n",
      "Training: Loss: 1.3646\n",
      "Epoch: 1051/1000\n",
      "Training: Loss: 1.3248\n",
      "Epoch: 1052/1000\n",
      "Training: Loss: 1.2906\n",
      "Epoch: 1053/1000\n",
      "Training: Loss: 1.3912\n",
      "Epoch: 1054/1000\n",
      "Training: Loss: 1.3982\n",
      "Epoch: 1055/1000\n",
      "Training: Loss: 1.3596\n",
      "Epoch: 1056/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.4239\n",
      "Epoch: 1057/1000\n",
      "Training: Loss: 1.4737\n",
      "Epoch: 1058/1000\n",
      "Training: Loss: 1.3979\n",
      "Epoch: 1059/1000\n",
      "Training: Loss: 1.3787\n",
      "Epoch: 1060/1000\n",
      "Training: Loss: 1.3222\n",
      "Epoch: 1061/1000\n",
      "Training: Loss: 1.5077\n",
      "Epoch: 1062/1000\n",
      "Training: Loss: 1.4315\n",
      "Epoch: 1063/1000\n",
      "Training: Loss: 1.3396\n",
      "Epoch: 1064/1000\n",
      "Training: Loss: 1.3665\n",
      "Epoch: 1065/1000\n",
      "Training: Loss: 1.3597\n",
      "Epoch: 1066/1000\n",
      "Training: Loss: 1.3689\n",
      "Epoch: 1067/1000\n",
      "Training: Loss: 1.4403\n",
      "Epoch: 1068/1000\n",
      "Training: Loss: 1.4178\n",
      "Epoch: 1069/1000\n",
      "Training: Loss: 1.3738\n",
      "Epoch: 1070/1000\n",
      "Training: Loss: 1.3533\n",
      "Epoch: 1071/1000\n",
      "Training: Loss: 1.3898\n",
      "Epoch: 1072/1000\n",
      "Training: Loss: 1.3516\n",
      "Epoch: 1073/1000\n",
      "Training: Loss: 1.3400\n",
      "Epoch: 1074/1000\n",
      "Training: Loss: 1.3238\n",
      "Epoch: 1075/1000\n",
      "Training: Loss: 1.5104\n",
      "Epoch: 1076/1000\n",
      "Training: Loss: 1.2677\n",
      "Epoch: 1077/1000\n",
      "Training: Loss: 1.4170\n",
      "Epoch: 1078/1000\n",
      "Training: Loss: 1.5051\n",
      "Epoch: 1079/1000\n",
      "Training: Loss: 1.4203\n",
      "Epoch: 1080/1000\n",
      "Training: Loss: 1.4748\n",
      "Epoch: 1081/1000\n",
      "Training: Loss: 1.4266\n",
      "Epoch: 1082/1000\n",
      "Training: Loss: 1.3414\n",
      "Epoch: 1083/1000\n",
      "Training: Loss: 1.3311\n",
      "Epoch: 1084/1000\n",
      "Training: Loss: 1.4381\n",
      "Epoch: 1085/1000\n",
      "Training: Loss: 1.3637\n",
      "Epoch: 1086/1000\n",
      "Training: Loss: 1.3604\n",
      "Epoch: 1087/1000\n",
      "Training: Loss: 1.3627\n",
      "Epoch: 1088/1000\n",
      "Training: Loss: 1.4218\n",
      "Epoch: 1089/1000\n",
      "Training: Loss: 1.3951\n",
      "Epoch: 1090/1000\n",
      "Training: Loss: 1.4076\n",
      "Epoch: 1091/1000\n",
      "Training: Loss: 1.3504\n",
      "Epoch: 1092/1000\n",
      "Training: Loss: 1.3435\n",
      "Epoch: 1093/1000\n",
      "Training: Loss: 1.3608\n",
      "Epoch: 1094/1000\n",
      "Training: Loss: 1.3971\n",
      "Epoch: 1095/1000\n",
      "Training: Loss: 1.3885\n",
      "Epoch: 1096/1000\n",
      "Training: Loss: 1.4232\n",
      "Epoch: 1097/1000\n",
      "Training: Loss: 1.3639\n",
      "Epoch: 1098/1000\n",
      "Training: Loss: 1.3280\n",
      "Epoch: 1099/1000\n",
      "Training: Loss: 1.3272\n",
      "Epoch: 1100/1000\n",
      "Training: Loss: 1.4737\n",
      "Epoch: 1101/1000\n",
      "Training: Loss: 1.3880\n",
      "Epoch: 1102/1000\n",
      "Training: Loss: 1.3819\n",
      "Epoch: 1103/1000\n",
      "Training: Loss: 1.4669\n",
      "Epoch: 1104/1000\n",
      "Training: Loss: 1.4278\n",
      "Epoch: 1105/1000\n",
      "Training: Loss: 1.3672\n",
      "Epoch: 1106/1000\n",
      "Training: Loss: 1.3962\n",
      "Epoch: 1107/1000\n",
      "Training: Loss: 1.3457\n",
      "Epoch: 1108/1000\n",
      "Training: Loss: 1.3853\n",
      "Epoch: 1109/1000\n",
      "Training: Loss: 1.4463\n",
      "Epoch: 1110/1000\n",
      "Training: Loss: 1.4206\n",
      "Epoch: 1111/1000\n",
      "Training: Loss: 1.3840\n",
      "Epoch: 1112/1000\n",
      "Training: Loss: 1.4304\n",
      "Epoch: 1113/1000\n",
      "Training: Loss: 1.4589\n",
      "Epoch: 1114/1000\n",
      "Training: Loss: 1.4285\n",
      "Epoch: 1115/1000\n",
      "Training: Loss: 1.3799\n",
      "Epoch: 1116/1000\n",
      "Training: Loss: 1.6273\n",
      "Epoch: 1117/1000\n",
      "Training: Loss: 1.3815\n",
      "Epoch: 1118/1000\n",
      "Training: Loss: 1.4085\n",
      "Epoch: 1119/1000\n",
      "Training: Loss: 1.4250\n",
      "Epoch: 1120/1000\n",
      "Training: Loss: 1.3340\n",
      "Epoch: 1121/1000\n",
      "Training: Loss: 1.3728\n",
      "Epoch: 1122/1000\n",
      "Training: Loss: 1.3862\n",
      "Epoch: 1123/1000\n",
      "Training: Loss: 1.3346\n",
      "Epoch: 1124/1000\n",
      "Training: Loss: 1.4164\n",
      "Epoch: 1125/1000\n",
      "Training: Loss: 1.4573\n",
      "Epoch: 1126/1000\n",
      "Training: Loss: 1.4575\n",
      "Epoch: 1127/1000\n",
      "Training: Loss: 1.2941\n",
      "Epoch: 1128/1000\n",
      "Training: Loss: 1.3631\n",
      "Epoch: 1129/1000\n",
      "Training: Loss: 1.3437\n",
      "Epoch: 1130/1000\n",
      "Training: Loss: 1.4474\n",
      "Epoch: 1131/1000\n",
      "Training: Loss: 1.3348\n",
      "Epoch: 1132/1000\n",
      "Training: Loss: 1.3320\n",
      "Epoch: 1133/1000\n",
      "Training: Loss: 1.4578\n",
      "Epoch: 1134/1000\n",
      "Training: Loss: 1.3005\n",
      "Epoch: 1135/1000\n",
      "Training: Loss: 1.3743\n",
      "Epoch: 1136/1000\n",
      "Training: Loss: 1.4646\n",
      "Epoch: 1137/1000\n",
      "Training: Loss: 1.4110\n",
      "Epoch: 1138/1000\n",
      "Training: Loss: 1.3977\n",
      "Epoch: 1139/1000\n",
      "Training: Loss: 1.4081\n",
      "Epoch: 1140/1000\n",
      "Training: Loss: 1.3986\n",
      "Epoch: 1141/1000\n",
      "Training: Loss: 1.3646\n",
      "Epoch: 1142/1000\n",
      "Training: Loss: 1.4241\n",
      "Epoch: 1143/1000\n",
      "Training: Loss: 1.3966\n",
      "Epoch: 1144/1000\n",
      "Training: Loss: 1.3949\n",
      "Epoch: 1145/1000\n",
      "Training: Loss: 1.4143\n",
      "Epoch: 1146/1000\n",
      "Training: Loss: 1.3909\n",
      "Epoch: 1147/1000\n",
      "Training: Loss: 1.3725\n",
      "Epoch: 1148/1000\n",
      "Training: Loss: 1.4436\n",
      "Epoch: 1149/1000\n",
      "Training: Loss: 1.3610\n",
      "Epoch: 1150/1000\n",
      "Training: Loss: 1.4661\n",
      "Epoch: 1151/1000\n",
      "Training: Loss: 1.4200\n",
      "Epoch: 1152/1000\n",
      "Training: Loss: 1.4342\n",
      "Epoch: 1153/1000\n",
      "Training: Loss: 1.4116\n",
      "Epoch: 1154/1000\n",
      "Training: Loss: 1.4334\n",
      "Epoch: 1155/1000\n",
      "Training: Loss: 1.3434\n",
      "Epoch: 1156/1000\n",
      "Training: Loss: 1.4041\n",
      "Epoch: 1157/1000\n",
      "Training: Loss: 1.3693\n",
      "Epoch: 1158/1000\n",
      "Training: Loss: 1.3716\n",
      "Epoch: 1159/1000\n",
      "Training: Loss: 1.4748\n",
      "Epoch: 1160/1000\n",
      "Training: Loss: 1.3584\n",
      "Epoch: 1161/1000\n",
      "Training: Loss: 1.3549\n",
      "Epoch: 1162/1000\n",
      "Training: Loss: 1.4017\n",
      "Epoch: 1163/1000\n",
      "Training: Loss: 1.3291\n",
      "Epoch: 1164/1000\n",
      "Training: Loss: 1.4740\n",
      "Epoch: 1165/1000\n",
      "Training: Loss: 1.3912\n",
      "Epoch: 1166/1000\n",
      "Training: Loss: 1.4034\n",
      "Epoch: 1167/1000\n",
      "Training: Loss: 1.4095\n",
      "Epoch: 1168/1000\n",
      "Training: Loss: 1.3804\n",
      "Epoch: 1169/1000\n",
      "Training: Loss: 1.3357\n",
      "Epoch: 1170/1000\n",
      "Training: Loss: 1.3326\n",
      "Epoch: 1171/1000\n",
      "Training: Loss: 1.4675\n",
      "Epoch: 1172/1000\n",
      "Training: Loss: 1.4065\n",
      "Epoch: 1173/1000\n",
      "Training: Loss: 1.3487\n",
      "Epoch: 1174/1000\n",
      "Training: Loss: 1.5308\n",
      "Epoch: 1175/1000\n",
      "Training: Loss: 1.3928\n",
      "Epoch: 1176/1000\n",
      "Training: Loss: 1.3638\n",
      "Epoch: 1177/1000\n",
      "Training: Loss: 1.4111\n",
      "Epoch: 1178/1000\n",
      "Training: Loss: 1.4338\n",
      "Epoch: 1179/1000\n",
      "Training: Loss: 1.3365\n",
      "Epoch: 1180/1000\n",
      "Training: Loss: 1.3792\n",
      "Epoch: 1181/1000\n",
      "Training: Loss: 1.4242\n",
      "Epoch: 1182/1000\n",
      "Training: Loss: 1.3738\n",
      "Epoch: 1183/1000\n",
      "Training: Loss: 1.3482\n",
      "Epoch: 1184/1000\n",
      "Training: Loss: 1.3951\n",
      "Epoch: 1185/1000\n",
      "Training: Loss: 1.3963\n",
      "Epoch: 1186/1000\n",
      "Training: Loss: 1.4456\n",
      "Epoch: 1187/1000\n",
      "Training: Loss: 1.3968\n",
      "Epoch: 1188/1000\n",
      "Training: Loss: 1.4529\n",
      "Epoch: 1189/1000\n",
      "Training: Loss: 1.4373\n",
      "Epoch: 1190/1000\n",
      "Training: Loss: 1.3917\n",
      "Epoch: 1191/1000\n",
      "Training: Loss: 1.3964\n",
      "Epoch: 1192/1000\n",
      "Training: Loss: 1.4494\n",
      "Epoch: 1193/1000\n",
      "Training: Loss: 1.4200\n",
      "Epoch: 1194/1000\n",
      "Training: Loss: 1.4098\n",
      "Epoch: 1195/1000\n",
      "Training: Loss: 1.3660\n",
      "Epoch: 1196/1000\n",
      "Training: Loss: 1.3365\n",
      "Epoch: 1197/1000\n",
      "Training: Loss: 1.3091\n",
      "Epoch: 1198/1000\n",
      "Training: Loss: 1.4133\n",
      "Epoch: 1199/1000\n",
      "Training: Loss: 1.4464\n",
      "Epoch: 1200/1000\n",
      "Training: Loss: 1.4762\n",
      "Epoch: 1201/1000\n",
      "Training: Loss: 1.3229\n",
      "Epoch: 1202/1000\n",
      "Training: Loss: 1.3969\n",
      "Epoch: 1203/1000\n",
      "Training: Loss: 1.3120\n",
      "Epoch: 1204/1000\n",
      "Training: Loss: 1.3340\n",
      "Epoch: 1205/1000\n",
      "Training: Loss: 1.4032\n",
      "Epoch: 1206/1000\n",
      "Training: Loss: 1.3616\n",
      "Epoch: 1207/1000\n",
      "Training: Loss: 1.3512\n",
      "Epoch: 1208/1000\n",
      "Training: Loss: 1.4540\n",
      "Epoch: 1209/1000\n",
      "Training: Loss: 1.3477\n",
      "Epoch: 1210/1000\n",
      "Training: Loss: 1.3817\n",
      "Epoch: 1211/1000\n",
      "Training: Loss: 1.5222\n",
      "Epoch: 1212/1000\n",
      "Training: Loss: 1.3583\n",
      "Epoch: 1213/1000\n",
      "Training: Loss: 1.4800\n",
      "Epoch: 1214/1000\n",
      "Training: Loss: 1.3353\n",
      "Epoch: 1215/1000\n",
      "Training: Loss: 1.4158\n",
      "Epoch: 1216/1000\n",
      "Training: Loss: 1.4679\n",
      "Epoch: 1217/1000\n",
      "Training: Loss: 1.4120\n",
      "Epoch: 1218/1000\n",
      "Training: Loss: 1.4096\n",
      "Epoch: 1219/1000\n",
      "Training: Loss: 1.4081\n",
      "Epoch: 1220/1000\n",
      "Training: Loss: 1.4134\n",
      "Epoch: 1221/1000\n",
      "Training: Loss: 1.3669\n",
      "Epoch: 1222/1000\n",
      "Training: Loss: 1.3290\n",
      "Epoch: 1223/1000\n",
      "Training: Loss: 1.3871\n",
      "Epoch: 1224/1000\n",
      "Training: Loss: 1.3454\n",
      "Epoch: 1225/1000\n",
      "Training: Loss: 1.4702\n",
      "Epoch: 1226/1000\n",
      "Training: Loss: 1.3901\n",
      "Epoch: 1227/1000\n",
      "Training: Loss: 1.4016\n",
      "Epoch: 1228/1000\n",
      "Training: Loss: 1.3708\n",
      "Epoch: 1229/1000\n",
      "Training: Loss: 1.3083\n",
      "Epoch: 1230/1000\n",
      "Training: Loss: 1.3703\n",
      "Epoch: 1231/1000\n",
      "Training: Loss: 1.3447\n",
      "Epoch: 1232/1000\n",
      "Training: Loss: 1.3796\n",
      "Epoch: 1233/1000\n",
      "Training: Loss: 1.4566\n",
      "Epoch: 1234/1000\n",
      "Training: Loss: 1.3662\n",
      "Epoch: 1235/1000\n",
      "Training: Loss: 1.5169\n",
      "Epoch: 1236/1000\n",
      "Training: Loss: 1.4528\n",
      "Epoch: 1237/1000\n",
      "Training: Loss: 1.3434\n",
      "Epoch: 1238/1000\n",
      "Training: Loss: 1.4069\n",
      "Epoch: 1239/1000\n",
      "Training: Loss: 1.3707\n",
      "Epoch: 1240/1000\n",
      "Training: Loss: 1.3267\n",
      "Epoch: 1241/1000\n",
      "Training: Loss: 1.3439\n",
      "Epoch: 1242/1000\n",
      "Training: Loss: 1.4594\n",
      "Epoch: 1243/1000\n",
      "Training: Loss: 1.3885\n",
      "Epoch: 1244/1000\n",
      "Training: Loss: 1.3566\n",
      "Epoch: 1245/1000\n",
      "Training: Loss: 1.4397\n",
      "Epoch: 1246/1000\n",
      "Training: Loss: 1.4061\n",
      "Epoch: 1247/1000\n",
      "Training: Loss: 1.4718\n",
      "Epoch: 1248/1000\n",
      "Training: Loss: 1.5612\n",
      "Epoch: 1249/1000\n",
      "Training: Loss: 1.4297\n",
      "Epoch: 1250/1000\n",
      "Training: Loss: 1.3815\n",
      "Epoch: 1251/1000\n",
      "Training: Loss: 1.4306\n",
      "Epoch: 1252/1000\n",
      "Training: Loss: 1.3184\n",
      "Epoch: 1253/1000\n",
      "Training: Loss: 1.3629\n",
      "Epoch: 1254/1000\n",
      "Training: Loss: 1.4614\n",
      "Epoch: 1255/1000\n",
      "Training: Loss: 1.4129\n",
      "Epoch: 1256/1000\n",
      "Training: Loss: 1.4053\n",
      "Epoch: 1257/1000\n",
      "Training: Loss: 1.3542\n",
      "Epoch: 1258/1000\n",
      "Training: Loss: 1.4359\n",
      "Epoch: 1259/1000\n",
      "Training: Loss: 1.4327\n",
      "Epoch: 1260/1000\n",
      "Training: Loss: 1.3269\n",
      "Epoch: 1261/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.4296\n",
      "Epoch: 1262/1000\n",
      "Training: Loss: 1.3838\n",
      "Epoch: 1263/1000\n",
      "Training: Loss: 1.4122\n",
      "Epoch: 1264/1000\n",
      "Training: Loss: 1.3858\n",
      "Epoch: 1265/1000\n",
      "Training: Loss: 1.4274\n",
      "Epoch: 1266/1000\n",
      "Training: Loss: 1.4057\n",
      "Epoch: 1267/1000\n",
      "Training: Loss: 1.4564\n",
      "Epoch: 1268/1000\n",
      "Training: Loss: 1.3638\n",
      "Epoch: 1269/1000\n",
      "Training: Loss: 1.3329\n",
      "Epoch: 1270/1000\n",
      "Training: Loss: 1.3708\n",
      "Epoch: 1271/1000\n",
      "Training: Loss: 1.3095\n",
      "Epoch: 1272/1000\n",
      "Training: Loss: 1.4474\n",
      "Epoch: 1273/1000\n",
      "Training: Loss: 1.5130\n",
      "Epoch: 1274/1000\n",
      "Training: Loss: 1.4632\n",
      "Epoch: 1275/1000\n",
      "Training: Loss: 1.3454\n",
      "Epoch: 1276/1000\n",
      "Training: Loss: 1.4469\n",
      "Epoch: 1277/1000\n",
      "Training: Loss: 1.4732\n",
      "Epoch: 1278/1000\n",
      "Training: Loss: 1.3596\n",
      "Epoch: 1279/1000\n",
      "Training: Loss: 1.4543\n",
      "Epoch: 1280/1000\n",
      "Training: Loss: 1.3940\n",
      "Epoch: 1281/1000\n",
      "Training: Loss: 1.3459\n",
      "Epoch: 1282/1000\n",
      "Training: Loss: 1.3739\n",
      "Epoch: 1283/1000\n",
      "Training: Loss: 1.3728\n",
      "Epoch: 1284/1000\n",
      "Training: Loss: 1.3996\n",
      "Epoch: 1285/1000\n",
      "Training: Loss: 1.4115\n",
      "Epoch: 1286/1000\n",
      "Training: Loss: 1.3462\n",
      "Epoch: 1287/1000\n",
      "Training: Loss: 1.3775\n",
      "Epoch: 1288/1000\n",
      "Training: Loss: 1.3511\n",
      "Epoch: 1289/1000\n",
      "Training: Loss: 1.3908\n",
      "Epoch: 1290/1000\n",
      "Training: Loss: 1.4282\n",
      "Epoch: 1291/1000\n",
      "Training: Loss: 1.3567\n",
      "Epoch: 1292/1000\n",
      "Training: Loss: 1.4552\n",
      "Epoch: 1293/1000\n",
      "Training: Loss: 1.4183\n",
      "Epoch: 1294/1000\n",
      "Training: Loss: 1.3115\n",
      "Epoch: 1295/1000\n",
      "Training: Loss: 1.4265\n",
      "Epoch: 1296/1000\n",
      "Training: Loss: 1.4428\n",
      "Epoch: 1297/1000\n",
      "Training: Loss: 1.4555\n",
      "Epoch: 1298/1000\n",
      "Training: Loss: 1.3664\n",
      "Epoch: 1299/1000\n",
      "Training: Loss: 1.3738\n",
      "Epoch: 1300/1000\n",
      "Training: Loss: 1.4195\n",
      "Epoch: 1301/1000\n",
      "Training: Loss: 1.3978\n",
      "Epoch: 1302/1000\n",
      "Training: Loss: 1.4072\n",
      "Epoch: 1303/1000\n",
      "Training: Loss: 1.4450\n",
      "Epoch: 1304/1000\n",
      "Training: Loss: 1.3734\n",
      "Epoch: 1305/1000\n",
      "Training: Loss: 1.3964\n",
      "Epoch: 1306/1000\n",
      "Training: Loss: 1.4149\n",
      "Epoch: 1307/1000\n",
      "Training: Loss: 1.3476\n",
      "Epoch: 1308/1000\n",
      "Training: Loss: 1.3818\n",
      "Epoch: 1309/1000\n",
      "Training: Loss: 1.3494\n",
      "Epoch: 1310/1000\n",
      "Training: Loss: 1.4378\n",
      "Epoch: 1311/1000\n",
      "Training: Loss: 1.3680\n",
      "Epoch: 1312/1000\n",
      "Training: Loss: 1.3362\n",
      "Epoch: 1313/1000\n",
      "Training: Loss: 1.4511\n",
      "Epoch: 1314/1000\n",
      "Training: Loss: 1.4504\n",
      "Epoch: 1315/1000\n",
      "Training: Loss: 1.3183\n",
      "Epoch: 1316/1000\n",
      "Training: Loss: 1.4904\n",
      "Epoch: 1317/1000\n",
      "Training: Loss: 1.3817\n",
      "Epoch: 1318/1000\n",
      "Training: Loss: 1.3481\n",
      "Epoch: 1319/1000\n",
      "Training: Loss: 1.4435\n",
      "Epoch: 1320/1000\n",
      "Training: Loss: 1.4505\n",
      "Epoch: 1321/1000\n",
      "Training: Loss: 1.4397\n",
      "Epoch: 1322/1000\n",
      "Training: Loss: 1.4807\n",
      "Epoch: 1323/1000\n",
      "Training: Loss: 1.4661\n",
      "Epoch: 1324/1000\n",
      "Training: Loss: 1.4424\n",
      "Epoch: 1325/1000\n",
      "Training: Loss: 1.4125\n",
      "Epoch: 1326/1000\n",
      "Training: Loss: 1.4334\n",
      "Epoch: 1327/1000\n",
      "Training: Loss: 1.3806\n",
      "Epoch: 1328/1000\n",
      "Training: Loss: 1.3144\n",
      "Epoch: 1329/1000\n",
      "Training: Loss: 1.3383\n",
      "Epoch: 1330/1000\n",
      "Training: Loss: 1.3672\n",
      "Epoch: 1331/1000\n",
      "Training: Loss: 1.3540\n",
      "Epoch: 1332/1000\n",
      "Training: Loss: 1.4383\n",
      "Epoch: 1333/1000\n",
      "Training: Loss: 1.4489\n",
      "Epoch: 1334/1000\n",
      "Training: Loss: 1.4519\n",
      "Epoch: 1335/1000\n",
      "Training: Loss: 1.3845\n",
      "Epoch: 1336/1000\n",
      "Training: Loss: 1.4338\n",
      "Epoch: 1337/1000\n",
      "Training: Loss: 1.4001\n",
      "Epoch: 1338/1000\n",
      "Training: Loss: 1.4450\n",
      "Epoch: 1339/1000\n",
      "Training: Loss: 1.4235\n",
      "Epoch: 1340/1000\n",
      "Training: Loss: 1.3948\n",
      "Epoch: 1341/1000\n",
      "Training: Loss: 1.4125\n",
      "Epoch: 1342/1000\n",
      "Training: Loss: 1.3988\n",
      "Epoch: 1343/1000\n",
      "Training: Loss: 1.4152\n",
      "Epoch: 1344/1000\n",
      "Training: Loss: 1.4343\n",
      "Epoch: 1345/1000\n",
      "Training: Loss: 1.4628\n",
      "Epoch: 1346/1000\n",
      "Training: Loss: 1.3952\n",
      "Epoch: 1347/1000\n",
      "Training: Loss: 1.3969\n",
      "Epoch: 1348/1000\n",
      "Training: Loss: 1.2956\n",
      "Epoch: 1349/1000\n",
      "Training: Loss: 1.3908\n",
      "Epoch: 1350/1000\n",
      "Training: Loss: 1.3714\n",
      "Epoch: 1351/1000\n",
      "Training: Loss: 1.4033\n",
      "Epoch: 1352/1000\n",
      "Training: Loss: 1.3905\n",
      "Epoch: 1353/1000\n",
      "Training: Loss: 1.3699\n",
      "Epoch: 1354/1000\n",
      "Training: Loss: 1.4237\n",
      "Epoch: 1355/1000\n",
      "Training: Loss: 1.4102\n",
      "Epoch: 1356/1000\n",
      "Training: Loss: 1.4768\n",
      "Epoch: 1357/1000\n",
      "Training: Loss: 1.4121\n",
      "Epoch: 1358/1000\n",
      "Training: Loss: 1.3622\n",
      "Epoch: 1359/1000\n",
      "Training: Loss: 1.3329\n",
      "Epoch: 1360/1000\n",
      "Training: Loss: 1.3786\n",
      "Epoch: 1361/1000\n",
      "Training: Loss: 1.5064\n",
      "Epoch: 1362/1000\n",
      "Training: Loss: 1.3856\n",
      "Epoch: 1363/1000\n",
      "Training: Loss: 1.3455\n",
      "Epoch: 1364/1000\n",
      "Training: Loss: 1.4213\n",
      "Epoch: 1365/1000\n",
      "Training: Loss: 1.5690\n",
      "Epoch: 1366/1000\n",
      "Training: Loss: 1.3448\n",
      "Epoch: 1367/1000\n",
      "Training: Loss: 1.4393\n",
      "Epoch: 1368/1000\n",
      "Training: Loss: 1.4908\n",
      "Epoch: 1369/1000\n",
      "Training: Loss: 1.4308\n",
      "Epoch: 1370/1000\n",
      "Training: Loss: 1.4422\n",
      "Epoch: 1371/1000\n",
      "Training: Loss: 1.4162\n",
      "Epoch: 1372/1000\n",
      "Training: Loss: 1.3159\n",
      "Epoch: 1373/1000\n",
      "Training: Loss: 1.3501\n",
      "Epoch: 1374/1000\n",
      "Training: Loss: 1.3345\n",
      "Epoch: 1375/1000\n",
      "Training: Loss: 1.5115\n",
      "Epoch: 1376/1000\n",
      "Training: Loss: 1.4459\n",
      "Epoch: 1377/1000\n",
      "Training: Loss: 1.3936\n",
      "Epoch: 1378/1000\n",
      "Training: Loss: 1.3685\n",
      "Epoch: 1379/1000\n",
      "Training: Loss: 1.3723\n",
      "Epoch: 1380/1000\n",
      "Training: Loss: 1.4593\n",
      "Epoch: 1381/1000\n",
      "Training: Loss: 1.4757\n",
      "Epoch: 1382/1000\n",
      "Training: Loss: 1.3231\n",
      "Epoch: 1383/1000\n",
      "Training: Loss: 1.4002\n",
      "Epoch: 1384/1000\n",
      "Training: Loss: 1.3807\n",
      "Epoch: 1385/1000\n",
      "Training: Loss: 1.3795\n",
      "Epoch: 1386/1000\n",
      "Training: Loss: 1.4158\n",
      "Epoch: 1387/1000\n",
      "Training: Loss: 1.3800\n",
      "Epoch: 1388/1000\n",
      "Training: Loss: 1.3155\n",
      "Epoch: 1389/1000\n",
      "Training: Loss: 1.3563\n",
      "Epoch: 1390/1000\n",
      "Training: Loss: 1.3532\n",
      "Epoch: 1391/1000\n",
      "Training: Loss: 1.4211\n",
      "Epoch: 1392/1000\n",
      "Training: Loss: 1.3417\n",
      "Epoch: 1393/1000\n",
      "Training: Loss: 1.4063\n",
      "Epoch: 1394/1000\n",
      "Training: Loss: 1.3771\n",
      "Epoch: 1395/1000\n",
      "Training: Loss: 1.3786\n",
      "Epoch: 1396/1000\n",
      "Training: Loss: 1.4305\n",
      "Epoch: 1397/1000\n",
      "Training: Loss: 1.3565\n",
      "Epoch: 1398/1000\n",
      "Training: Loss: 1.3505\n",
      "Epoch: 1399/1000\n",
      "Training: Loss: 1.4197\n",
      "Epoch: 1400/1000\n",
      "Training: Loss: 1.4302\n",
      "Epoch: 1401/1000\n",
      "Training: Loss: 1.4284\n",
      "Epoch: 1402/1000\n",
      "Training: Loss: 1.4169\n",
      "Epoch: 1403/1000\n",
      "Training: Loss: 1.4295\n",
      "Epoch: 1404/1000\n",
      "Training: Loss: 1.3269\n",
      "Epoch: 1405/1000\n",
      "Training: Loss: 1.4669\n",
      "Epoch: 1406/1000\n",
      "Training: Loss: 1.4700\n",
      "Epoch: 1407/1000\n",
      "Training: Loss: 1.4608\n",
      "Epoch: 1408/1000\n",
      "Training: Loss: 1.3226\n",
      "Epoch: 1409/1000\n",
      "Training: Loss: 1.3507\n",
      "Epoch: 1410/1000\n",
      "Training: Loss: 1.4826\n",
      "Epoch: 1411/1000\n",
      "Training: Loss: 1.4465\n",
      "Epoch: 1412/1000\n",
      "Training: Loss: 1.3833\n",
      "Epoch: 1413/1000\n",
      "Training: Loss: 1.4392\n",
      "Epoch: 1414/1000\n",
      "Training: Loss: 1.5799\n",
      "Epoch: 1415/1000\n",
      "Training: Loss: 1.4046\n",
      "Epoch: 1416/1000\n",
      "Training: Loss: 1.4321\n",
      "Epoch: 1417/1000\n",
      "Training: Loss: 1.4361\n",
      "Epoch: 1418/1000\n",
      "Training: Loss: 1.3728\n",
      "Epoch: 1419/1000\n",
      "Training: Loss: 1.3281\n",
      "Epoch: 1420/1000\n",
      "Training: Loss: 1.3775\n",
      "Epoch: 1421/1000\n",
      "Training: Loss: 1.3267\n",
      "Epoch: 1422/1000\n",
      "Training: Loss: 1.4417\n",
      "Epoch: 1423/1000\n",
      "Training: Loss: 1.3887\n",
      "Epoch: 1424/1000\n",
      "Training: Loss: 1.3195\n",
      "Epoch: 1425/1000\n",
      "Training: Loss: 1.3878\n",
      "Epoch: 1426/1000\n",
      "Training: Loss: 1.4264\n",
      "Epoch: 1427/1000\n",
      "Training: Loss: 1.3923\n",
      "Epoch: 1428/1000\n",
      "Training: Loss: 1.4210\n",
      "Epoch: 1429/1000\n",
      "Training: Loss: 1.4248\n",
      "Epoch: 1430/1000\n",
      "Training: Loss: 1.4358\n",
      "Epoch: 1431/1000\n",
      "Training: Loss: 1.3209\n",
      "Epoch: 1432/1000\n",
      "Training: Loss: 1.3301\n",
      "Epoch: 1433/1000\n",
      "Training: Loss: 1.3231\n",
      "Epoch: 1434/1000\n",
      "Training: Loss: 1.2842\n",
      "Epoch: 1435/1000\n",
      "Training: Loss: 1.4667\n",
      "Epoch: 1436/1000\n",
      "Training: Loss: 1.4322\n",
      "Epoch: 1437/1000\n",
      "Training: Loss: 1.4531\n",
      "Epoch: 1438/1000\n",
      "Training: Loss: 1.3493\n",
      "Epoch: 1439/1000\n",
      "Training: Loss: 1.4806\n",
      "Epoch: 1440/1000\n",
      "Training: Loss: 1.3797\n",
      "Epoch: 1441/1000\n",
      "Training: Loss: 1.3731\n",
      "Epoch: 1442/1000\n",
      "Training: Loss: 1.3623\n",
      "Epoch: 1443/1000\n",
      "Training: Loss: 1.4701\n",
      "Epoch: 1444/1000\n",
      "Training: Loss: 1.3333\n",
      "Epoch: 1445/1000\n",
      "Training: Loss: 1.3771\n",
      "Epoch: 1446/1000\n",
      "Training: Loss: 1.3602\n",
      "Epoch: 1447/1000\n",
      "Training: Loss: 1.3959\n",
      "Epoch: 1448/1000\n",
      "Training: Loss: 1.4032\n",
      "Epoch: 1449/1000\n",
      "Training: Loss: 1.3497\n",
      "Epoch: 1450/1000\n",
      "Training: Loss: 1.3596\n",
      "Epoch: 1451/1000\n",
      "Training: Loss: 1.5591\n",
      "Epoch: 1452/1000\n",
      "Training: Loss: 1.3908\n",
      "Epoch: 1453/1000\n",
      "Training: Loss: 1.4230\n",
      "Epoch: 1454/1000\n",
      "Training: Loss: 1.4902\n",
      "Epoch: 1455/1000\n",
      "Training: Loss: 1.4406\n",
      "Epoch: 1456/1000\n",
      "Training: Loss: 1.3596\n",
      "Epoch: 1457/1000\n",
      "Training: Loss: 1.3246\n",
      "Epoch: 1458/1000\n",
      "Training: Loss: 1.4605\n",
      "Epoch: 1459/1000\n",
      "Training: Loss: 1.3908\n",
      "Epoch: 1460/1000\n",
      "Training: Loss: 1.4397\n",
      "Epoch: 1461/1000\n",
      "Training: Loss: 1.3590\n",
      "Epoch: 1462/1000\n",
      "Training: Loss: 1.3583\n",
      "Epoch: 1463/1000\n",
      "Training: Loss: 1.3635\n",
      "Epoch: 1464/1000\n",
      "Training: Loss: 1.3993\n",
      "Epoch: 1465/1000\n",
      "Training: Loss: 1.3197\n",
      "Epoch: 1466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.3840\n",
      "Epoch: 1467/1000\n",
      "Training: Loss: 1.3678\n",
      "Epoch: 1468/1000\n",
      "Training: Loss: 1.4112\n",
      "Epoch: 1469/1000\n",
      "Training: Loss: 1.3996\n",
      "Epoch: 1470/1000\n",
      "Training: Loss: 1.3848\n",
      "Epoch: 1471/1000\n",
      "Training: Loss: 1.4180\n",
      "Epoch: 1472/1000\n",
      "Training: Loss: 1.3758\n",
      "Epoch: 1473/1000\n",
      "Training: Loss: 1.4028\n",
      "Epoch: 1474/1000\n",
      "Training: Loss: 1.3161\n",
      "Epoch: 1475/1000\n",
      "Training: Loss: 1.3738\n",
      "Epoch: 1476/1000\n",
      "Training: Loss: 1.4178\n",
      "Epoch: 1477/1000\n",
      "Training: Loss: 1.3732\n",
      "Epoch: 1478/1000\n",
      "Training: Loss: 1.3607\n",
      "Epoch: 1479/1000\n",
      "Training: Loss: 1.4167\n",
      "Epoch: 1480/1000\n",
      "Training: Loss: 1.3441\n",
      "Epoch: 1481/1000\n",
      "Training: Loss: 1.4008\n",
      "Epoch: 1482/1000\n",
      "Training: Loss: 1.4181\n",
      "Epoch: 1483/1000\n",
      "Training: Loss: 1.3782\n",
      "Epoch: 1484/1000\n",
      "Training: Loss: 1.4022\n",
      "Epoch: 1485/1000\n",
      "Training: Loss: 1.4030\n",
      "Epoch: 1486/1000\n",
      "Training: Loss: 1.3230\n",
      "Epoch: 1487/1000\n",
      "Training: Loss: 1.4386\n",
      "Epoch: 1488/1000\n",
      "Training: Loss: 1.4632\n",
      "Epoch: 1489/1000\n",
      "Training: Loss: 1.3782\n",
      "Epoch: 1490/1000\n",
      "Training: Loss: 1.3681\n",
      "Epoch: 1491/1000\n",
      "Training: Loss: 1.4271\n",
      "Epoch: 1492/1000\n",
      "Training: Loss: 1.4288\n",
      "Epoch: 1493/1000\n",
      "Training: Loss: 1.4247\n",
      "Epoch: 1494/1000\n",
      "Training: Loss: 1.3491\n",
      "Epoch: 1495/1000\n",
      "Training: Loss: 1.3814\n",
      "Epoch: 1496/1000\n",
      "Training: Loss: 1.3590\n",
      "Epoch: 1497/1000\n",
      "Training: Loss: 1.2969\n",
      "Epoch: 1498/1000\n",
      "Training: Loss: 1.3799\n",
      "Epoch: 1499/1000\n",
      "Training: Loss: 1.4262\n",
      "Epoch: 1500/1000\n",
      "Training: Loss: 1.4340\n",
      "Epoch: 1501/1000\n",
      "Training: Loss: 1.4679\n",
      "Epoch: 1502/1000\n",
      "Training: Loss: 1.3546\n",
      "Epoch: 1503/1000\n",
      "Training: Loss: 1.3128\n",
      "Epoch: 1504/1000\n",
      "Training: Loss: 1.4986\n",
      "Epoch: 1505/1000\n",
      "Training: Loss: 1.4622\n",
      "Epoch: 1506/1000\n",
      "Training: Loss: 1.3900\n",
      "Epoch: 1507/1000\n",
      "Training: Loss: 1.3700\n",
      "Epoch: 1508/1000\n",
      "Training: Loss: 1.3493\n",
      "Epoch: 1509/1000\n",
      "Training: Loss: 1.3945\n",
      "Epoch: 1510/1000\n",
      "Training: Loss: 1.3788\n",
      "Epoch: 1511/1000\n",
      "Training: Loss: 1.3900\n",
      "Epoch: 1512/1000\n",
      "Training: Loss: 1.2981\n",
      "Epoch: 1513/1000\n",
      "Training: Loss: 1.4287\n",
      "Epoch: 1514/1000\n",
      "Training: Loss: 1.4009\n",
      "Epoch: 1515/1000\n",
      "Training: Loss: 1.4534\n",
      "Epoch: 1516/1000\n",
      "Training: Loss: 1.3239\n",
      "Epoch: 1517/1000\n",
      "Training: Loss: 1.4819\n",
      "Epoch: 1518/1000\n",
      "Training: Loss: 1.4610\n",
      "Epoch: 1519/1000\n",
      "Training: Loss: 1.4344\n",
      "Epoch: 1520/1000\n",
      "Training: Loss: 1.4143\n",
      "Epoch: 1521/1000\n",
      "Training: Loss: 1.3188\n",
      "Epoch: 1522/1000\n",
      "Training: Loss: 1.4435\n",
      "Epoch: 1523/1000\n",
      "Training: Loss: 1.4025\n",
      "Epoch: 1524/1000\n",
      "Training: Loss: 1.4170\n",
      "Epoch: 1525/1000\n",
      "Training: Loss: 1.3775\n",
      "Epoch: 1526/1000\n",
      "Training: Loss: 1.3857\n",
      "Epoch: 1527/1000\n",
      "Training: Loss: 1.3363\n",
      "Epoch: 1528/1000\n",
      "Training: Loss: 1.4636\n",
      "Epoch: 1529/1000\n",
      "Training: Loss: 1.3960\n",
      "Epoch: 1530/1000\n",
      "Training: Loss: 1.4648\n",
      "Epoch: 1531/1000\n",
      "Training: Loss: 1.3831\n",
      "Epoch: 1532/1000\n",
      "Training: Loss: 1.4303\n",
      "Epoch: 1533/1000\n",
      "Training: Loss: 1.4478\n",
      "Epoch: 1534/1000\n",
      "Training: Loss: 1.3942\n",
      "Epoch: 1535/1000\n",
      "Training: Loss: 1.3519\n",
      "Epoch: 1536/1000\n",
      "Training: Loss: 1.4295\n",
      "Epoch: 1537/1000\n",
      "Training: Loss: 1.4120\n",
      "Epoch: 1538/1000\n",
      "Training: Loss: 1.3563\n",
      "Epoch: 1539/1000\n",
      "Training: Loss: 1.4066\n",
      "Epoch: 1540/1000\n",
      "Training: Loss: 1.3817\n",
      "Epoch: 1541/1000\n",
      "Training: Loss: 1.3544\n",
      "Epoch: 1542/1000\n",
      "Training: Loss: 1.4360\n",
      "Epoch: 1543/1000\n",
      "Training: Loss: 1.3763\n",
      "Epoch: 1544/1000\n",
      "Training: Loss: 1.3606\n",
      "Epoch: 1545/1000\n",
      "Training: Loss: 1.4039\n",
      "Epoch: 1546/1000\n",
      "Training: Loss: 1.3563\n",
      "Epoch: 1547/1000\n",
      "Training: Loss: 1.3037\n",
      "Epoch: 1548/1000\n",
      "Training: Loss: 1.3838\n",
      "Epoch: 1549/1000\n",
      "Training: Loss: 1.3719\n",
      "Epoch: 1550/1000\n",
      "Training: Loss: 1.4557\n",
      "Epoch: 1551/1000\n",
      "Training: Loss: 1.4004\n",
      "Epoch: 1552/1000\n",
      "Training: Loss: 1.4115\n",
      "Epoch: 1553/1000\n",
      "Training: Loss: 1.3742\n",
      "Epoch: 1554/1000\n",
      "Training: Loss: 1.4361\n",
      "Epoch: 1555/1000\n",
      "Training: Loss: 1.4630\n",
      "Epoch: 1556/1000\n",
      "Training: Loss: 1.3297\n",
      "Epoch: 1557/1000\n",
      "Training: Loss: 1.3690\n",
      "Epoch: 1558/1000\n",
      "Training: Loss: 1.3905\n",
      "Epoch: 1559/1000\n",
      "Training: Loss: 1.4201\n",
      "Epoch: 1560/1000\n",
      "Training: Loss: 1.4028\n",
      "Epoch: 1561/1000\n",
      "Training: Loss: 1.4180\n",
      "Epoch: 1562/1000\n",
      "Training: Loss: 1.4156\n",
      "Epoch: 1563/1000\n",
      "Training: Loss: 1.4449\n",
      "Epoch: 1564/1000\n",
      "Training: Loss: 1.2789\n",
      "Epoch: 1565/1000\n",
      "Training: Loss: 1.3585\n",
      "Epoch: 1566/1000\n",
      "Training: Loss: 1.3510\n",
      "Epoch: 1567/1000\n",
      "Training: Loss: 1.3596\n",
      "Epoch: 1568/1000\n",
      "Training: Loss: 1.2791\n",
      "Epoch: 1569/1000\n",
      "Training: Loss: 1.4119\n",
      "Epoch: 1570/1000\n",
      "Training: Loss: 1.3626\n",
      "Epoch: 1571/1000\n",
      "Training: Loss: 1.4358\n",
      "Epoch: 1572/1000\n",
      "Training: Loss: 1.4034\n",
      "Epoch: 1573/1000\n",
      "Training: Loss: 1.3786\n",
      "Epoch: 1574/1000\n",
      "Training: Loss: 1.3064\n",
      "Epoch: 1575/1000\n",
      "Training: Loss: 1.4096\n",
      "Epoch: 1576/1000\n",
      "Training: Loss: 1.4295\n",
      "Epoch: 1577/1000\n",
      "Training: Loss: 1.3867\n",
      "Epoch: 1578/1000\n",
      "Training: Loss: 1.4014\n",
      "Epoch: 1579/1000\n",
      "Training: Loss: 1.4278\n",
      "Epoch: 1580/1000\n",
      "Training: Loss: 1.4976\n",
      "Epoch: 1581/1000\n",
      "Training: Loss: 1.4329\n",
      "Epoch: 1582/1000\n",
      "Training: Loss: 1.3964\n",
      "Epoch: 1583/1000\n",
      "Training: Loss: 1.4654\n",
      "Epoch: 1584/1000\n",
      "Training: Loss: 1.3315\n",
      "Epoch: 1585/1000\n",
      "Training: Loss: 1.4025\n",
      "Epoch: 1586/1000\n",
      "Training: Loss: 1.2854\n",
      "Epoch: 1587/1000\n",
      "Training: Loss: 1.3568\n",
      "Epoch: 1588/1000\n",
      "Training: Loss: 1.4060\n",
      "Epoch: 1589/1000\n",
      "Training: Loss: 1.3871\n",
      "Epoch: 1590/1000\n",
      "Training: Loss: 1.4594\n",
      "Epoch: 1591/1000\n",
      "Training: Loss: 1.4419\n",
      "Epoch: 1592/1000\n",
      "Training: Loss: 1.3986\n",
      "Epoch: 1593/1000\n",
      "Training: Loss: 1.3841\n",
      "Epoch: 1594/1000\n",
      "Training: Loss: 1.2955\n",
      "Epoch: 1595/1000\n",
      "Training: Loss: 1.3235\n",
      "Epoch: 1596/1000\n",
      "Training: Loss: 1.3774\n",
      "Epoch: 1597/1000\n",
      "Training: Loss: 1.3653\n",
      "Epoch: 1598/1000\n",
      "Training: Loss: 1.4078\n",
      "Epoch: 1599/1000\n",
      "Training: Loss: 1.4026\n",
      "Epoch: 1600/1000\n",
      "Training: Loss: 1.4116\n",
      "Epoch: 1601/1000\n",
      "Training: Loss: 1.4528\n",
      "Epoch: 1602/1000\n",
      "Training: Loss: 1.3791\n",
      "Epoch: 1603/1000\n",
      "Training: Loss: 1.3772\n",
      "Epoch: 1604/1000\n",
      "Training: Loss: 1.3572\n",
      "Epoch: 1605/1000\n",
      "Training: Loss: 1.4156\n",
      "Epoch: 1606/1000\n",
      "Training: Loss: 1.3511\n",
      "Epoch: 1607/1000\n",
      "Training: Loss: 1.3749\n",
      "Epoch: 1608/1000\n",
      "Training: Loss: 1.4178\n",
      "Epoch: 1609/1000\n",
      "Training: Loss: 1.3922\n",
      "Epoch: 1610/1000\n",
      "Training: Loss: 1.3637\n",
      "Epoch: 1611/1000\n",
      "Training: Loss: 1.4205\n",
      "Epoch: 1612/1000\n",
      "Training: Loss: 1.4453\n",
      "Epoch: 1613/1000\n",
      "Training: Loss: 1.3786\n",
      "Epoch: 1614/1000\n",
      "Training: Loss: 1.3704\n",
      "Epoch: 1615/1000\n",
      "Training: Loss: 1.2863\n",
      "Epoch: 1616/1000\n",
      "Training: Loss: 1.3600\n",
      "Epoch: 1617/1000\n",
      "Training: Loss: 1.4315\n",
      "Epoch: 1618/1000\n",
      "Training: Loss: 1.4302\n",
      "Epoch: 1619/1000\n",
      "Training: Loss: 1.3574\n",
      "Epoch: 1620/1000\n",
      "Training: Loss: 1.3846\n",
      "Epoch: 1621/1000\n",
      "Training: Loss: 1.4509\n",
      "Epoch: 1622/1000\n",
      "Training: Loss: 1.3335\n",
      "Epoch: 1623/1000\n",
      "Training: Loss: 1.4076\n",
      "Epoch: 1624/1000\n",
      "Training: Loss: 1.3974\n",
      "Epoch: 1625/1000\n",
      "Training: Loss: 1.3534\n",
      "Epoch: 1626/1000\n",
      "Training: Loss: 1.3898\n",
      "Epoch: 1627/1000\n",
      "Training: Loss: 1.4442\n",
      "Epoch: 1628/1000\n",
      "Training: Loss: 1.4238\n",
      "Epoch: 1629/1000\n",
      "Training: Loss: 1.3141\n",
      "Epoch: 1630/1000\n",
      "Training: Loss: 1.4364\n",
      "Epoch: 1631/1000\n",
      "Training: Loss: 1.3743\n",
      "Epoch: 1632/1000\n",
      "Training: Loss: 1.4081\n",
      "Epoch: 1633/1000\n",
      "Training: Loss: 1.4574\n",
      "Epoch: 1634/1000\n",
      "Training: Loss: 1.3959\n",
      "Epoch: 1635/1000\n",
      "Training: Loss: 1.3960\n",
      "Epoch: 1636/1000\n",
      "Training: Loss: 1.3375\n",
      "Epoch: 1637/1000\n",
      "Training: Loss: 1.3564\n",
      "Epoch: 1638/1000\n",
      "Training: Loss: 1.4312\n",
      "Epoch: 1639/1000\n",
      "Training: Loss: 1.4841\n",
      "Epoch: 1640/1000\n",
      "Training: Loss: 1.4053\n",
      "Epoch: 1641/1000\n",
      "Training: Loss: 1.3465\n",
      "Epoch: 1642/1000\n",
      "Training: Loss: 1.4245\n",
      "Epoch: 1643/1000\n",
      "Training: Loss: 1.4976\n",
      "Epoch: 1644/1000\n",
      "Training: Loss: 1.3271\n",
      "Epoch: 1645/1000\n",
      "Training: Loss: 1.4019\n",
      "Epoch: 1646/1000\n",
      "Training: Loss: 1.4489\n",
      "Epoch: 1647/1000\n",
      "Training: Loss: 1.4273\n",
      "Epoch: 1648/1000\n",
      "Training: Loss: 1.4345\n",
      "Epoch: 1649/1000\n",
      "Training: Loss: 1.3574\n",
      "Epoch: 1650/1000\n",
      "Training: Loss: 1.3953\n",
      "Epoch: 1651/1000\n",
      "Training: Loss: 1.4898\n",
      "Epoch: 1652/1000\n",
      "Training: Loss: 1.3526\n",
      "Epoch: 1653/1000\n",
      "Training: Loss: 1.3860\n",
      "Epoch: 1654/1000\n",
      "Training: Loss: 1.4497\n",
      "Epoch: 1655/1000\n",
      "Training: Loss: 1.4310\n",
      "Epoch: 1656/1000\n",
      "Training: Loss: 1.3506\n",
      "Epoch: 1657/1000\n",
      "Training: Loss: 1.3934\n",
      "Epoch: 1658/1000\n",
      "Training: Loss: 1.3584\n",
      "Epoch: 1659/1000\n",
      "Training: Loss: 1.3613\n",
      "Epoch: 1660/1000\n",
      "Training: Loss: 1.5461\n",
      "Epoch: 1661/1000\n",
      "Training: Loss: 1.3265\n",
      "Epoch: 1662/1000\n",
      "Training: Loss: 1.3846\n",
      "Epoch: 1663/1000\n",
      "Training: Loss: 1.4236\n",
      "Epoch: 1664/1000\n",
      "Training: Loss: 1.4935\n",
      "Epoch: 1665/1000\n",
      "Training: Loss: 1.3776\n",
      "Epoch: 1666/1000\n",
      "Training: Loss: 1.3632\n",
      "Epoch: 1667/1000\n",
      "Training: Loss: 1.3902\n",
      "Epoch: 1668/1000\n",
      "Training: Loss: 1.3509\n",
      "Epoch: 1669/1000\n",
      "Training: Loss: 1.3323\n",
      "Epoch: 1670/1000\n",
      "Training: Loss: 1.3855\n",
      "Epoch: 1671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.3427\n",
      "Epoch: 1672/1000\n",
      "Training: Loss: 1.4028\n",
      "Epoch: 1673/1000\n",
      "Training: Loss: 1.3767\n",
      "Epoch: 1674/1000\n",
      "Training: Loss: 1.3411\n",
      "Epoch: 1675/1000\n",
      "Training: Loss: 1.3263\n",
      "Epoch: 1676/1000\n",
      "Training: Loss: 1.4002\n",
      "Epoch: 1677/1000\n",
      "Training: Loss: 1.3385\n",
      "Epoch: 1678/1000\n",
      "Training: Loss: 1.2680\n",
      "Epoch: 1679/1000\n",
      "Training: Loss: 1.4041\n",
      "Epoch: 1680/1000\n",
      "Training: Loss: 1.3677\n",
      "Epoch: 1681/1000\n",
      "Training: Loss: 1.3075\n",
      "Epoch: 1682/1000\n",
      "Training: Loss: 1.3792\n",
      "Epoch: 1683/1000\n",
      "Training: Loss: 1.3677\n",
      "Epoch: 1684/1000\n",
      "Training: Loss: 1.4351\n",
      "Epoch: 1685/1000\n",
      "Training: Loss: 1.4213\n",
      "Epoch: 1686/1000\n",
      "Training: Loss: 1.3341\n",
      "Epoch: 1687/1000\n",
      "Training: Loss: 1.3632\n",
      "Epoch: 1688/1000\n",
      "Training: Loss: 1.3753\n",
      "Epoch: 1689/1000\n",
      "Training: Loss: 1.3437\n",
      "Epoch: 1690/1000\n",
      "Training: Loss: 1.3811\n",
      "Epoch: 1691/1000\n",
      "Training: Loss: 1.4575\n",
      "Epoch: 1692/1000\n",
      "Training: Loss: 1.3441\n",
      "Epoch: 1693/1000\n",
      "Training: Loss: 1.3942\n",
      "Epoch: 1694/1000\n",
      "Training: Loss: 1.3272\n",
      "Epoch: 1695/1000\n",
      "Training: Loss: 1.3416\n",
      "Epoch: 1696/1000\n",
      "Training: Loss: 1.4954\n",
      "Epoch: 1697/1000\n",
      "Training: Loss: 1.4584\n",
      "Epoch: 1698/1000\n",
      "Training: Loss: 1.4043\n",
      "Epoch: 1699/1000\n",
      "Training: Loss: 1.4178\n",
      "Epoch: 1700/1000\n",
      "Training: Loss: 1.3683\n",
      "Epoch: 1701/1000\n",
      "Training: Loss: 1.2677\n",
      "Epoch: 1702/1000\n",
      "Training: Loss: 1.3791\n",
      "Epoch: 1703/1000\n",
      "Training: Loss: 1.3796\n",
      "Epoch: 1704/1000\n",
      "Training: Loss: 1.3883\n",
      "Epoch: 1705/1000\n",
      "Training: Loss: 1.3902\n",
      "Epoch: 1706/1000\n",
      "Training: Loss: 1.3897\n",
      "Epoch: 1707/1000\n",
      "Training: Loss: 1.3621\n",
      "Epoch: 1708/1000\n",
      "Training: Loss: 1.4102\n",
      "Epoch: 1709/1000\n",
      "Training: Loss: 1.3926\n",
      "Epoch: 1710/1000\n",
      "Training: Loss: 1.3648\n",
      "Epoch: 1711/1000\n",
      "Training: Loss: 1.3386\n",
      "Epoch: 1712/1000\n",
      "Training: Loss: 1.3280\n",
      "Epoch: 1713/1000\n",
      "Training: Loss: 1.3815\n",
      "Epoch: 1714/1000\n",
      "Training: Loss: 1.5473\n",
      "Epoch: 1715/1000\n",
      "Training: Loss: 1.4460\n",
      "Epoch: 1716/1000\n",
      "Training: Loss: 1.3549\n",
      "Epoch: 1717/1000\n",
      "Training: Loss: 1.3939\n",
      "Epoch: 1718/1000\n",
      "Training: Loss: 1.4481\n",
      "Epoch: 1719/1000\n",
      "Training: Loss: 1.3659\n",
      "Epoch: 1720/1000\n",
      "Training: Loss: 1.4518\n",
      "Epoch: 1721/1000\n",
      "Training: Loss: 1.3929\n",
      "Epoch: 1722/1000\n",
      "Training: Loss: 1.3500\n",
      "Epoch: 1723/1000\n",
      "Training: Loss: 1.3958\n",
      "Epoch: 1724/1000\n",
      "Training: Loss: 1.4674\n",
      "Epoch: 1725/1000\n",
      "Training: Loss: 1.4333\n",
      "Epoch: 1726/1000\n",
      "Training: Loss: 1.3633\n",
      "Epoch: 1727/1000\n",
      "Training: Loss: 1.3636\n",
      "Epoch: 1728/1000\n",
      "Training: Loss: 1.4385\n",
      "Epoch: 1729/1000\n",
      "Training: Loss: 1.4929\n",
      "Epoch: 1730/1000\n",
      "Training: Loss: 1.3942\n",
      "Epoch: 1731/1000\n",
      "Training: Loss: 1.4325\n",
      "Epoch: 1732/1000\n",
      "Training: Loss: 1.3606\n",
      "Epoch: 1733/1000\n",
      "Training: Loss: 1.4542\n",
      "Epoch: 1734/1000\n",
      "Training: Loss: 1.4724\n",
      "Epoch: 1735/1000\n",
      "Training: Loss: 1.4076\n",
      "Epoch: 1736/1000\n",
      "Training: Loss: 1.3478\n",
      "Epoch: 1737/1000\n",
      "Training: Loss: 1.2942\n",
      "Epoch: 1738/1000\n",
      "Training: Loss: 1.3586\n",
      "Epoch: 1739/1000\n",
      "Training: Loss: 1.3255\n",
      "Epoch: 1740/1000\n",
      "Training: Loss: 1.4007\n",
      "Epoch: 1741/1000\n",
      "Training: Loss: 1.3998\n",
      "Epoch: 1742/1000\n",
      "Training: Loss: 1.3821\n",
      "Epoch: 1743/1000\n",
      "Training: Loss: 1.4589\n",
      "Epoch: 1744/1000\n",
      "Training: Loss: 1.4000\n",
      "Epoch: 1745/1000\n",
      "Training: Loss: 1.3101\n",
      "Epoch: 1746/1000\n",
      "Training: Loss: 1.3938\n",
      "Epoch: 1747/1000\n",
      "Training: Loss: 1.4626\n",
      "Epoch: 1748/1000\n",
      "Training: Loss: 1.3752\n",
      "Epoch: 1749/1000\n",
      "Training: Loss: 1.3324\n",
      "Epoch: 1750/1000\n",
      "Training: Loss: 1.4365\n",
      "Epoch: 1751/1000\n",
      "Training: Loss: 1.4170\n",
      "Epoch: 1752/1000\n",
      "Training: Loss: 1.4145\n",
      "Epoch: 1753/1000\n",
      "Training: Loss: 1.4503\n",
      "Epoch: 1754/1000\n",
      "Training: Loss: 1.3673\n",
      "Epoch: 1755/1000\n",
      "Training: Loss: 1.5040\n",
      "Epoch: 1756/1000\n",
      "Training: Loss: 1.4029\n",
      "Epoch: 1757/1000\n",
      "Training: Loss: 1.4636\n",
      "Epoch: 1758/1000\n",
      "Training: Loss: 1.3261\n",
      "Epoch: 1759/1000\n",
      "Training: Loss: 1.3931\n",
      "Epoch: 1760/1000\n",
      "Training: Loss: 1.4516\n",
      "Epoch: 1761/1000\n",
      "Training: Loss: 1.4286\n",
      "Epoch: 1762/1000\n",
      "Training: Loss: 1.4604\n",
      "Epoch: 1763/1000\n",
      "Training: Loss: 1.4083\n",
      "Epoch: 1764/1000\n",
      "Training: Loss: 1.3165\n",
      "Epoch: 1765/1000\n",
      "Training: Loss: 1.3648\n",
      "Epoch: 1766/1000\n",
      "Training: Loss: 1.3423\n",
      "Epoch: 1767/1000\n",
      "Training: Loss: 1.3694\n",
      "Epoch: 1768/1000\n",
      "Training: Loss: 1.3714\n",
      "Epoch: 1769/1000\n",
      "Training: Loss: 1.3961\n",
      "Epoch: 1770/1000\n",
      "Training: Loss: 1.4113\n",
      "Epoch: 1771/1000\n",
      "Training: Loss: 1.3408\n",
      "Epoch: 1772/1000\n",
      "Training: Loss: 1.4353\n",
      "Epoch: 1773/1000\n",
      "Training: Loss: 1.3911\n",
      "Epoch: 1774/1000\n",
      "Training: Loss: 1.4191\n",
      "Epoch: 1775/1000\n",
      "Training: Loss: 1.4214\n",
      "Epoch: 1776/1000\n",
      "Training: Loss: 1.4030\n",
      "Epoch: 1777/1000\n",
      "Training: Loss: 1.3784\n",
      "Epoch: 1778/1000\n",
      "Training: Loss: 1.3584\n",
      "Epoch: 1779/1000\n",
      "Training: Loss: 1.4116\n",
      "Epoch: 1780/1000\n",
      "Training: Loss: 1.3887\n",
      "Epoch: 1781/1000\n",
      "Training: Loss: 1.3511\n",
      "Epoch: 1782/1000\n",
      "Training: Loss: 1.4192\n",
      "Epoch: 1783/1000\n",
      "Training: Loss: 1.4497\n",
      "Epoch: 1784/1000\n",
      "Training: Loss: 1.3556\n",
      "Epoch: 1785/1000\n",
      "Training: Loss: 1.3959\n",
      "Epoch: 1786/1000\n",
      "Training: Loss: 1.3585\n",
      "Epoch: 1787/1000\n",
      "Training: Loss: 1.3362\n",
      "Epoch: 1788/1000\n",
      "Training: Loss: 1.4424\n",
      "Epoch: 1789/1000\n",
      "Training: Loss: 1.4770\n",
      "Epoch: 1790/1000\n",
      "Training: Loss: 1.3319\n",
      "Epoch: 1791/1000\n",
      "Training: Loss: 1.3912\n",
      "Epoch: 1792/1000\n",
      "Training: Loss: 1.4401\n",
      "Epoch: 1793/1000\n",
      "Training: Loss: 1.3917\n",
      "Epoch: 1794/1000\n",
      "Training: Loss: 1.3755\n",
      "Epoch: 1795/1000\n",
      "Training: Loss: 1.4489\n",
      "Epoch: 1796/1000\n",
      "Training: Loss: 1.3862\n",
      "Epoch: 1797/1000\n",
      "Training: Loss: 1.3527\n",
      "Epoch: 1798/1000\n",
      "Training: Loss: 1.3688\n",
      "Epoch: 1799/1000\n",
      "Training: Loss: 1.3570\n",
      "Epoch: 1800/1000\n",
      "Training: Loss: 1.4378\n",
      "Epoch: 1801/1000\n",
      "Training: Loss: 1.3876\n",
      "Epoch: 1802/1000\n",
      "Training: Loss: 1.3800\n",
      "Epoch: 1803/1000\n",
      "Training: Loss: 1.3854\n",
      "Epoch: 1804/1000\n",
      "Training: Loss: 1.3028\n",
      "Epoch: 1805/1000\n",
      "Training: Loss: 1.3955\n",
      "Epoch: 1806/1000\n",
      "Training: Loss: 1.3321\n",
      "Epoch: 1807/1000\n",
      "Training: Loss: 1.4176\n",
      "Epoch: 1808/1000\n",
      "Training: Loss: 1.4150\n",
      "Epoch: 1809/1000\n",
      "Training: Loss: 1.3987\n",
      "Epoch: 1810/1000\n",
      "Training: Loss: 1.3557\n",
      "Epoch: 1811/1000\n",
      "Training: Loss: 1.4016\n",
      "Epoch: 1812/1000\n",
      "Training: Loss: 1.4618\n",
      "Epoch: 1813/1000\n",
      "Training: Loss: 1.3999\n",
      "Epoch: 1814/1000\n",
      "Training: Loss: 1.4504\n",
      "Epoch: 1815/1000\n",
      "Training: Loss: 1.3846\n",
      "Epoch: 1816/1000\n",
      "Training: Loss: 1.4468\n",
      "Epoch: 1817/1000\n",
      "Training: Loss: 1.4820\n",
      "Epoch: 1818/1000\n",
      "Training: Loss: 1.4105\n",
      "Epoch: 1819/1000\n",
      "Training: Loss: 1.2991\n",
      "Epoch: 1820/1000\n",
      "Training: Loss: 1.4340\n",
      "Epoch: 1821/1000\n",
      "Training: Loss: 1.3581\n",
      "Epoch: 1822/1000\n",
      "Training: Loss: 1.3334\n",
      "Epoch: 1823/1000\n",
      "Training: Loss: 1.3207\n",
      "Epoch: 1824/1000\n",
      "Training: Loss: 1.4597\n",
      "Epoch: 1825/1000\n",
      "Training: Loss: 1.3802\n",
      "Epoch: 1826/1000\n",
      "Training: Loss: 1.3764\n",
      "Epoch: 1827/1000\n",
      "Training: Loss: 1.4302\n",
      "Epoch: 1828/1000\n",
      "Training: Loss: 1.3903\n",
      "Epoch: 1829/1000\n",
      "Training: Loss: 1.3632\n",
      "Epoch: 1830/1000\n",
      "Training: Loss: 1.3249\n",
      "Epoch: 1831/1000\n",
      "Training: Loss: 1.5140\n",
      "Epoch: 1832/1000\n",
      "Training: Loss: 1.4186\n",
      "Epoch: 1833/1000\n",
      "Training: Loss: 1.3390\n",
      "Epoch: 1834/1000\n",
      "Training: Loss: 1.4887\n",
      "Epoch: 1835/1000\n",
      "Training: Loss: 1.4164\n",
      "Epoch: 1836/1000\n",
      "Training: Loss: 1.4093\n",
      "Epoch: 1837/1000\n",
      "Training: Loss: 1.3025\n",
      "Epoch: 1838/1000\n",
      "Training: Loss: 1.4231\n",
      "Epoch: 1839/1000\n",
      "Training: Loss: 1.3197\n",
      "Epoch: 1840/1000\n",
      "Training: Loss: 1.3952\n",
      "Epoch: 1841/1000\n",
      "Training: Loss: 1.2970\n",
      "Epoch: 1842/1000\n",
      "Training: Loss: 1.4210\n",
      "Epoch: 1843/1000\n",
      "Training: Loss: 1.4395\n",
      "Epoch: 1844/1000\n",
      "Training: Loss: 1.4520\n",
      "Epoch: 1845/1000\n",
      "Training: Loss: 1.3311\n",
      "Epoch: 1846/1000\n",
      "Training: Loss: 1.4060\n",
      "Epoch: 1847/1000\n",
      "Training: Loss: 1.3748\n",
      "Epoch: 1848/1000\n",
      "Training: Loss: 1.3513\n",
      "Epoch: 1849/1000\n",
      "Training: Loss: 1.3636\n",
      "Epoch: 1850/1000\n",
      "Training: Loss: 1.3405\n",
      "Epoch: 1851/1000\n",
      "Training: Loss: 1.2703\n",
      "Epoch: 1852/1000\n",
      "Training: Loss: 1.4324\n",
      "Epoch: 1853/1000\n",
      "Training: Loss: 1.2948\n",
      "Epoch: 1854/1000\n",
      "Training: Loss: 1.4215\n",
      "Epoch: 1855/1000\n",
      "Training: Loss: 1.4389\n",
      "Epoch: 1856/1000\n",
      "Training: Loss: 1.2873\n",
      "Epoch: 1857/1000\n",
      "Training: Loss: 1.3535\n",
      "Epoch: 1858/1000\n",
      "Training: Loss: 1.4116\n",
      "Epoch: 1859/1000\n",
      "Training: Loss: 1.4056\n",
      "Epoch: 1860/1000\n",
      "Training: Loss: 1.3948\n",
      "Epoch: 1861/1000\n",
      "Training: Loss: 1.4266\n",
      "Epoch: 1862/1000\n",
      "Training: Loss: 1.4479\n",
      "Epoch: 1863/1000\n",
      "Training: Loss: 1.4455\n",
      "Epoch: 1864/1000\n",
      "Training: Loss: 1.3344\n",
      "Epoch: 1865/1000\n",
      "Training: Loss: 1.4052\n",
      "Epoch: 1866/1000\n",
      "Training: Loss: 1.3088\n",
      "Epoch: 1867/1000\n",
      "Training: Loss: 1.3997\n",
      "Epoch: 1868/1000\n",
      "Training: Loss: 1.4250\n",
      "Epoch: 1869/1000\n",
      "Training: Loss: 1.4355\n",
      "Epoch: 1870/1000\n",
      "Training: Loss: 1.4035\n",
      "Epoch: 1871/1000\n",
      "Training: Loss: 1.4117\n",
      "Epoch: 1872/1000\n",
      "Training: Loss: 1.4101\n",
      "Epoch: 1873/1000\n",
      "Training: Loss: 1.3277\n",
      "Epoch: 1874/1000\n",
      "Training: Loss: 1.3317\n",
      "Epoch: 1875/1000\n",
      "Training: Loss: 1.3539\n",
      "Epoch: 1876/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Loss: 1.3984\n",
      "Epoch: 1877/1000\n",
      "Training: Loss: 1.3708\n",
      "Epoch: 1878/1000\n",
      "Training: Loss: 1.3142\n",
      "Epoch: 1879/1000\n",
      "Training: Loss: 1.3966\n",
      "Epoch: 1880/1000\n",
      "Training: Loss: 1.2764\n",
      "Epoch: 1881/1000\n",
      "Training: Loss: 1.4103\n",
      "Epoch: 1882/1000\n",
      "Training: Loss: 1.4145\n",
      "Epoch: 1883/1000\n",
      "Training: Loss: 1.4668\n",
      "Epoch: 1884/1000\n",
      "Training: Loss: 1.3904\n",
      "Epoch: 1885/1000\n",
      "Training: Loss: 1.4418\n",
      "Epoch: 1886/1000\n",
      "Training: Loss: 1.4123\n",
      "Epoch: 1887/1000\n",
      "Training: Loss: 1.3853\n",
      "Epoch: 1888/1000\n",
      "Training: Loss: 1.3747\n",
      "Epoch: 1889/1000\n",
      "Training: Loss: 1.4091\n",
      "Epoch: 1890/1000\n",
      "Training: Loss: 1.3753\n",
      "Epoch: 1891/1000\n",
      "Training: Loss: 1.3661\n",
      "Epoch: 1892/1000\n",
      "Training: Loss: 1.4160\n",
      "Epoch: 1893/1000\n",
      "Training: Loss: 1.3797\n",
      "Epoch: 1894/1000\n",
      "Training: Loss: 1.4129\n",
      "Epoch: 1895/1000\n",
      "Training: Loss: 1.3959\n",
      "Epoch: 1896/1000\n",
      "Training: Loss: 1.3074\n",
      "Epoch: 1897/1000\n",
      "Training: Loss: 1.3214\n",
      "Epoch: 1898/1000\n",
      "Training: Loss: 1.3811\n",
      "Epoch: 1899/1000\n",
      "Training: Loss: 1.3174\n",
      "Epoch: 1900/1000\n",
      "Training: Loss: 1.4429\n",
      "Epoch: 1901/1000\n",
      "Training: Loss: 1.3465\n",
      "Epoch: 1902/1000\n",
      "Training: Loss: 1.4022\n",
      "Epoch: 1903/1000\n",
      "Training: Loss: 1.4713\n",
      "Epoch: 1904/1000\n",
      "Training: Loss: 1.4668\n",
      "Epoch: 1905/1000\n",
      "Training: Loss: 1.3529\n",
      "Epoch: 1906/1000\n",
      "Training: Loss: 1.3137\n",
      "Epoch: 1907/1000\n",
      "Training: Loss: 1.4250\n",
      "Epoch: 1908/1000\n",
      "Training: Loss: 1.3129\n",
      "Epoch: 1909/1000\n",
      "Training: Loss: 1.2709\n",
      "Epoch: 1910/1000\n",
      "Training: Loss: 1.3398\n",
      "Epoch: 1911/1000\n",
      "Training: Loss: 1.3528\n",
      "Epoch: 1912/1000\n",
      "Training: Loss: 1.3965\n",
      "Epoch: 1913/1000\n",
      "Training: Loss: 1.4126\n",
      "Epoch: 1914/1000\n",
      "Training: Loss: 1.3150\n",
      "Epoch: 1915/1000\n",
      "Training: Loss: 1.4104\n",
      "Epoch: 1916/1000\n",
      "Training: Loss: 1.3789\n",
      "Epoch: 1917/1000\n",
      "Training: Loss: 1.4302\n",
      "Epoch: 1918/1000\n",
      "Training: Loss: 1.3498\n",
      "Epoch: 1919/1000\n",
      "Training: Loss: 1.5144\n",
      "Epoch: 1920/1000\n",
      "Training: Loss: 1.4454\n",
      "Epoch: 1921/1000\n",
      "Training: Loss: 1.4956\n",
      "Epoch: 1922/1000\n",
      "Training: Loss: 1.4779\n",
      "Epoch: 1923/1000\n",
      "Training: Loss: 1.3480\n",
      "Epoch: 1924/1000\n",
      "Training: Loss: 1.3835\n",
      "Epoch: 1925/1000\n",
      "Training: Loss: 1.4335\n",
      "Epoch: 1926/1000\n",
      "Training: Loss: 1.4007\n",
      "Epoch: 1927/1000\n",
      "Training: Loss: 1.3941\n",
      "Epoch: 1928/1000\n",
      "Training: Loss: 1.4524\n",
      "Epoch: 1929/1000\n",
      "Training: Loss: 1.4524\n",
      "Epoch: 1930/1000\n",
      "Training: Loss: 1.4026\n",
      "Epoch: 1931/1000\n",
      "Training: Loss: 1.3516\n",
      "Epoch: 1932/1000\n",
      "Training: Loss: 1.4013\n",
      "Epoch: 1933/1000\n",
      "Training: Loss: 1.3308\n",
      "Epoch: 1934/1000\n",
      "Training: Loss: 1.3829\n",
      "Epoch: 1935/1000\n",
      "Training: Loss: 1.4437\n",
      "Epoch: 1936/1000\n",
      "Training: Loss: 1.3641\n",
      "Epoch: 1937/1000\n",
      "Training: Loss: 1.4569\n",
      "Epoch: 1938/1000\n",
      "Training: Loss: 1.3925\n",
      "Epoch: 1939/1000\n",
      "Training: Loss: 1.4626\n",
      "Epoch: 1940/1000\n",
      "Training: Loss: 1.4259\n",
      "Epoch: 1941/1000\n",
      "Training: Loss: 1.3959\n",
      "Epoch: 1942/1000\n",
      "Training: Loss: 1.4182\n",
      "Epoch: 1943/1000\n",
      "Training: Loss: 1.3777\n",
      "Epoch: 1944/1000\n",
      "Training: Loss: 1.3827\n",
      "Epoch: 1945/1000\n",
      "Training: Loss: 1.4152\n",
      "Epoch: 1946/1000\n",
      "Training: Loss: 1.3949\n",
      "Epoch: 1947/1000\n",
      "Training: Loss: 1.3880\n",
      "Epoch: 1948/1000\n",
      "Training: Loss: 1.3612\n",
      "Epoch: 1949/1000\n",
      "Training: Loss: 1.3707\n",
      "Epoch: 1950/1000\n",
      "Training: Loss: 1.4755\n",
      "Epoch: 1951/1000\n",
      "Training: Loss: 1.4400\n",
      "Epoch: 1952/1000\n",
      "Training: Loss: 1.3398\n",
      "Epoch: 1953/1000\n",
      "Training: Loss: 1.3501\n",
      "Epoch: 1954/1000\n",
      "Training: Loss: 1.3562\n",
      "Epoch: 1955/1000\n",
      "Training: Loss: 1.3939\n",
      "Epoch: 1956/1000\n",
      "Training: Loss: 1.4073\n",
      "Epoch: 1957/1000\n",
      "Training: Loss: 1.4556\n",
      "Epoch: 1958/1000\n",
      "Training: Loss: 1.2852\n",
      "Epoch: 1959/1000\n",
      "Training: Loss: 1.3393\n",
      "Epoch: 1960/1000\n",
      "Training: Loss: 1.4047\n",
      "Epoch: 1961/1000\n",
      "Training: Loss: 1.3921\n",
      "Epoch: 1962/1000\n",
      "Training: Loss: 1.3810\n",
      "Epoch: 1963/1000\n",
      "Training: Loss: 1.3612\n",
      "Epoch: 1964/1000\n",
      "Training: Loss: 1.5173\n",
      "Epoch: 1965/1000\n",
      "Training: Loss: 1.4457\n",
      "Epoch: 1966/1000\n",
      "Training: Loss: 1.4354\n",
      "Epoch: 1967/1000\n",
      "Training: Loss: 1.3014\n",
      "Epoch: 1968/1000\n",
      "Training: Loss: 1.2566\n",
      "Epoch: 1969/1000\n",
      "Training: Loss: 1.3930\n",
      "Epoch: 1970/1000\n",
      "Training: Loss: 1.3782\n",
      "Epoch: 1971/1000\n",
      "Training: Loss: 1.3826\n",
      "Epoch: 1972/1000\n",
      "Training: Loss: 1.3753\n",
      "Epoch: 1973/1000\n",
      "Training: Loss: 1.4480\n",
      "Epoch: 1974/1000\n",
      "Training: Loss: 1.4377\n",
      "Epoch: 1975/1000\n",
      "Training: Loss: 1.3503\n",
      "Epoch: 1976/1000\n",
      "Training: Loss: 1.4000\n",
      "Epoch: 1977/1000\n",
      "Training: Loss: 1.4318\n",
      "Epoch: 1978/1000\n",
      "Training: Loss: 1.3608\n",
      "Epoch: 1979/1000\n",
      "Training: Loss: 1.3777\n",
      "Epoch: 1980/1000\n",
      "Training: Loss: 1.3468\n",
      "Epoch: 1981/1000\n",
      "Training: Loss: 1.3974\n",
      "Epoch: 1982/1000\n",
      "Training: Loss: 1.3693\n",
      "Epoch: 1983/1000\n",
      "Training: Loss: 1.3824\n",
      "Epoch: 1984/1000\n",
      "Training: Loss: 1.3904\n",
      "Epoch: 1985/1000\n",
      "Training: Loss: 1.3256\n",
      "Epoch: 1986/1000\n",
      "Training: Loss: 1.3951\n",
      "Epoch: 1987/1000\n",
      "Training: Loss: 1.4312\n",
      "Epoch: 1988/1000\n",
      "Training: Loss: 1.4312\n",
      "Epoch: 1989/1000\n",
      "Training: Loss: 1.4103\n",
      "Epoch: 1990/1000\n",
      "Training: Loss: 1.3266\n",
      "Epoch: 1991/1000\n",
      "Training: Loss: 1.3540\n",
      "Epoch: 1992/1000\n",
      "Training: Loss: 1.4192\n",
      "Epoch: 1993/1000\n",
      "Training: Loss: 1.4007\n",
      "Epoch: 1994/1000\n",
      "Training: Loss: 1.4516\n",
      "Epoch: 1995/1000\n",
      "Training: Loss: 1.3979\n",
      "Epoch: 1996/1000\n",
      "Training: Loss: 1.3390\n",
      "Epoch: 1997/1000\n",
      "Training: Loss: 1.2776\n",
      "Epoch: 1998/1000\n",
      "Training: Loss: 1.3877\n",
      "Epoch: 1999/1000\n",
      "Training: Loss: 1.3426\n",
      "Epoch: 2000/1000\n",
      "Training: Loss: 1.4253\n",
      "CPU times: user 2h 11min 19s, sys: 8min 3s, total: 2h 19min 22s\n",
      "Wall time: 2h 23min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(2000): #4100\n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, 1000))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_data):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Training: Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, l in test_data:\n",
    "    images = i\n",
    "    label = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, l in test_data:\n",
    "    images = i\n",
    "    label = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in test_data:\n",
    "    images = i\n",
    "    label = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, l in test_data:\n",
    "    images = i\n",
    "    label = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([247, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, label.shape\n",
    "pred = model(images.to(device))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 3, 5, 0, 4, 2, 4, 3, 5, 4, 5, 5, 4, 4, 5, 4, 4, 2, 5, 4, 3, 0, 3,\n",
       "        5, 4, 5, 0, 3, 5, 0, 5, 5, 5, 3, 2, 5, 5, 4, 3, 3, 5, 3, 2, 5, 5, 3, 5,\n",
       "        4, 4, 5, 2, 5, 4, 5, 4, 5, 5, 5, 5, 3, 4, 4, 2, 4, 5, 4, 5, 5, 3, 5, 5,\n",
       "        4, 4, 2, 4, 0, 3, 2, 4, 3, 5, 2, 4, 5, 3, 3, 5, 3, 5, 5, 3, 3, 2, 5, 5,\n",
       "        5, 5, 5, 5, 0, 3, 5, 3, 3, 0, 5, 2, 5, 5, 5, 4, 5, 2, 3, 5, 5, 5, 3, 5,\n",
       "        5, 3, 5, 4, 5, 3, 4, 5, 2, 5, 5, 4, 3, 3, 3, 0, 5, 3, 5, 6, 4, 5, 5, 5,\n",
       "        6, 5, 5, 4, 4, 2, 3, 5, 6, 5, 3, 3, 4, 0, 3, 5, 3, 3, 4, 4, 5, 5, 0, 3,\n",
       "        5, 3, 2, 5, 2, 5, 4, 3, 6, 0, 5, 6, 0, 5, 5, 3, 5, 5, 5, 4, 3, 3, 5, 3,\n",
       "        2, 5, 6, 5, 5, 3, 5, 5, 5, 4, 4, 0, 3, 4, 5, 5, 5, 5, 4, 5, 3, 3, 0, 5,\n",
       "        4, 5, 4, 5, 5, 0, 4, 5, 5, 5, 5, 6, 4, 5, 3, 5, 5, 5, 4, 0, 6, 5, 4, 3,\n",
       "        5, 5, 0, 4, 2, 5, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([x.argmax() for x in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29554655870445345"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sum(torch.tensor([x.argmax() for x in pred]) == label)) / 247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 2, 4, 6, 3, 2, 3, 6, 0, 2, 0, 1, 5, 0, 3, 3, 2, 3, 4, 4, 4, 1, 0,\n",
       "        5, 5, 6, 4, 0, 1, 1, 5, 2, 1, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = model(inputs[0:2])\n",
    "loss_func(a, labels[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'EmotionClassificationCNN.2100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34.class_to_idx = data['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
